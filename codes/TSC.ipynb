{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch    \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#set figure size\n",
    "sns.set(rc={'figure.figsize':(10,5)})\n",
    "#darkgrid, whitegrid, dark, white, and ticks\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1352580, 8)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'D:\\vscode_workspace\\PracticeLab\\IMU_concat2.txt', sep='\\t', header = 0)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3072, 946)\n"
     ]
    }
   ],
   "source": [
    "df_1 = pd.read_csv(r'D:\\个人文档\\各种文档\\04-快走-1.calc', header=2, delim_whitespace=True)\n",
    "\n",
    "print(df_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>01-X-x</th>\n",
       "      <th>01-X-y</th>\n",
       "      <th>01-X-z</th>\n",
       "      <th>01-V-x</th>\n",
       "      <th>01-V-y</th>\n",
       "      <th>01-V-z</th>\n",
       "      <th>01-Q-s</th>\n",
       "      <th>01-Q-x</th>\n",
       "      <th>01-Q-y</th>\n",
       "      <th>01-Q-z</th>\n",
       "      <th>...</th>\n",
       "      <th>59-Q-s</th>\n",
       "      <th>59-Q-x</th>\n",
       "      <th>59-Q-y</th>\n",
       "      <th>59-Q-z</th>\n",
       "      <th>59-A-x</th>\n",
       "      <th>59-A-y</th>\n",
       "      <th>59-A-z</th>\n",
       "      <th>59-W-x</th>\n",
       "      <th>59-W-y</th>\n",
       "      <th>59-W-z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1110</td>\n",
       "      <td>0.3511</td>\n",
       "      <td>0.8498</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>-2.8863</td>\n",
       "      <td>0.7354</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.6776</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1109</td>\n",
       "      <td>0.3512</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>-0.0054</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>-2.8861</td>\n",
       "      <td>0.7355</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.6775</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.1108</td>\n",
       "      <td>0.3514</td>\n",
       "      <td>0.8502</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>-2.8867</td>\n",
       "      <td>0.7355</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.6776</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.1107</td>\n",
       "      <td>0.3516</td>\n",
       "      <td>0.8504</td>\n",
       "      <td>-0.0016</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>-2.8869</td>\n",
       "      <td>0.7355</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.6776</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.1106</td>\n",
       "      <td>0.3518</td>\n",
       "      <td>0.8506</td>\n",
       "      <td>-0.0023</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>-2.8858</td>\n",
       "      <td>0.7355</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.6776</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 946 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   01-X-x  01-X-y  01-X-z  01-V-x  01-V-y  01-V-z  01-Q-s  01-Q-x  01-Q-y  \\\n",
       "0  1.1110  0.3511  0.8498  0.0008  0.0072 -2.8863  0.7354  0.0045  0.0034   \n",
       "1  1.1109  0.3512  0.8500 -0.0054  0.0063 -2.8861  0.7355  0.0045  0.0034   \n",
       "2  1.1108  0.3514  0.8502 -0.0006  0.0020 -2.8867  0.7355  0.0045  0.0033   \n",
       "3  1.1107  0.3516  0.8504 -0.0016  0.0087 -2.8869  0.7355  0.0045  0.0033   \n",
       "4  1.1106  0.3518  0.8506 -0.0023  0.0081 -2.8858  0.7355  0.0045  0.0033   \n",
       "\n",
       "   01-Q-z  ...  59-Q-s  59-Q-x  59-Q-y  59-Q-z  59-A-x  59-A-y  59-A-z  \\\n",
       "0  0.6776  ...     1.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1  0.6775  ...     1.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2  0.6776  ...     1.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3  0.6776  ...     1.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4  0.6776  ...     1.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   59-W-x  59-W-y  59-W-z  \n",
       "0     0.0     0.0     0.0  \n",
       "1     0.0     0.0     0.0  \n",
       "2     0.0     0.0     0.0  \n",
       "3     0.0     0.0     0.0  \n",
       "4     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 946 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352, 128)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = pd.read_csv(r'D:\\vscode_workspace\\PracticeLab\\IMU\\code\\dataset\\UCI HAR Dataset\\train\\Inertial Signals\\body_acc_x_train.txt', header=None, delim_whitespace=True)\n",
    "\n",
    "df_1.shape\n",
    "\n",
    "# df_1 = pd.read_csv(r'D:\\vscode_workspace\\PracticeLab\\IMU\\code\\dataset\\UCI HAR Dataset\\train\\X_train.txt', header=None, delim_whitespace=True)\n",
    "\n",
    "# print(df_1.shape)\n",
    "\n",
    "# df_1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by = ['user'], ignore_index=True)\n",
    "\n",
    "# train data -> Users upto User ID = 3 (i.e. 3 users)\n",
    "df_train = df[df['user'] <= 3]\n",
    "# test data -> Users ID = 4 (i.e. 1 users)\n",
    "df_test = df[df['user'] > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainy = df_train.type\n",
    "testy = df_test.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = df_train.drop(labels='type', axis=1)\n",
    "testX = df_test.drop(labels='type', axis=1)\n",
    "trainX = trainX.drop(labels='user', axis=1)\n",
    "testX = testX.drop(labels='user', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1003788, 6), (1003788,), (348792, 6), (348792,))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape, trainy.shape, testX.shape, testy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "# np.unique(label_encoder.fit_transform(df_train.type))\n",
    "# label_encoder.fit_transform(df_test.type)\n",
    "\n",
    "trainy = label_encoder.fit_transform(df_train.type)\n",
    "testy = label_encoder.fit_transform(df_test.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1003788, 6), (1003788,), (348792, 6), (348792,))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape, trainy.shape, testX.shape, testy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_list = list()\n",
    "\n",
    "for i in trainX.columns:\n",
    "    column = trainX.loc[:, i]\n",
    "    # if len(index_list) == 0:\n",
    "    index_list = index_list.append(column)\n",
    "    # else:\n",
    "    #     index_list = np.hstack(column)\n",
    "\n",
    "print(len(index_list))\n",
    "print(np.dstack(np.array(index_list)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6, 1003788)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dstack(np.array(trainX)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         -0.3320\n",
       "1         -0.1172\n",
       "2         -0.1172\n",
       "3         -0.1133\n",
       "4         -0.1133\n",
       "            ...  \n",
       "1003783    0.0000\n",
       "1003784    0.0000\n",
       "1003785    0.1571\n",
       "1003786    0.0175\n",
       "1003787    0.0524\n",
       "Name: A-x, Length: 1003788, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.loc[:, trainX.columns[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         -0.3320\n",
       "1         -0.1172\n",
       "2         -0.1172\n",
       "3         -0.1133\n",
       "4         -0.1133\n",
       "            ...  \n",
       "1003783    0.0000\n",
       "1003784    0.0000\n",
       "1003785    0.1571\n",
       "1003786    0.0175\n",
       "1003787    0.0524\n",
       "Name: A-x, Length: 1003788, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.loc[:, 'A-x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "(6, 1003788)\n",
      "(6, 1003788)\n",
      "(1, 1003788, 6)\n"
     ]
    }
   ],
   "source": [
    "index_list = list()\n",
    "\n",
    "for i in trainX.columns:\n",
    "    column = trainX.loc[:, i]\n",
    "    index_list.append(column)\n",
    "\n",
    "print(len(index_list))\n",
    "print(np.array(trainX).T.shape)\n",
    "print(np.array(index_list).shape)\n",
    "print(np.dstack(np.array(index_list)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 1003788, 1)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(trainX).T.reshape(np.array(trainX).T.shape[0], np.array(trainX).T.shape[1], 1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6022728,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack(np.array(trainX)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before dstack\n",
      "(1003788, 6) (1003788,)\n",
      "after dstack\n",
      "(1003788, 1, 6) (1, 1, 1003788)\n",
      "loading\n",
      "(1003788, 1, 6) (1003788, 4) (348792, 6) (348792, 4)\n",
      "after load:\n",
      "(1003788, 1, 6) (1003788, 4) (348792, 6) (348792, 4)\n",
      "(1003788, 1, 6)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 194\u001b[0m\n\u001b[0;32m    192\u001b[0m trainyT \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(trainy)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m    193\u001b[0m testXT \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(testX)\n\u001b[1;32m--> 194\u001b[0m testXT \u001b[38;5;241m=\u001b[39m \u001b[43mtestXT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m    195\u001b[0m testyT \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(testy)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m    196\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib\n",
    "# matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# load a single file as a numpy array\n",
    "# def load_file(filepath):\n",
    "#     dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
    "#     return dataframe.values\n",
    "\n",
    "# load a list of files into a 3D array of [samples, timesteps, features]\n",
    "# def load_group(filenames, prefix=''):\n",
    "#     # group train, test\n",
    "#     # prefix -> 'D:/vscode_workspace/PracticeLab/IMU/code/dataset/UCI HAR Dataset/group/Inertial Signals/'\n",
    "#     loaded = list()\n",
    "#     for name in filenames:\n",
    "#         data = load_file(prefix + name)\n",
    "#         loaded.append(data)\n",
    "#     # stack group so that features are the 3rd dimension\n",
    "#     loaded = np.dstack(loaded)\n",
    "#     print('loaded.shape:', loaded.shape)\n",
    "#     return loaded  # loaded.shape: (7352, 128, 9)\n",
    "\n",
    "# load a dataset group, such as train or test\n",
    "# def load_dataset_group(group, prefix=''):\n",
    "#     # prefix -> 'D:/vscode_workspace/PracticeLab/IMU/code/dataset/UCI HAR Dataset/'\n",
    "#     # group train, test\n",
    "#     filepath = prefix + group + '/Inertial Signals/' # get the signals path\n",
    "#     # load all 9 files as a single array\n",
    "#     filenames = list()\n",
    "#     # total acceleration\n",
    "#     filenames += ['total_acc_x_' + group + '.txt', 'total_acc_y_' + group + '.txt', 'total_acc_z_' + group + '.txt']\n",
    "#     # body acceleration\n",
    "#     filenames += ['body_acc_x_' + group + '.txt', 'body_acc_y_' + group + '.txt', 'body_acc_z_' + group + '.txt']\n",
    "#     # body gyroscope\n",
    "#     filenames += ['body_gyro_x_' + group + '.txt', 'body_gyro_y_' + group + '.txt', 'body_gyro_z_' + group + '.txt']\n",
    "#     # filenames save all signals' filename\n",
    "#     # load input data\n",
    "#     X = load_group(filenames, filepath) # loaded.shape: (7352, 128, 9) train,   loaded.shape: (2947, 128, 9)  test\n",
    "#     # load class output\n",
    "#     y = load_file(prefix + group + '/y_' + group + '.txt') # y_train.txt, y_test.txt\n",
    "#     return X, y # X_train y_train;  X_test, y_test\n",
    "\n",
    "def to_categorical(y, num_classes=None, dtype='float32'):\n",
    "    \"\"\"Converts a class vector (integers) to binary class matrix.\n",
    "    E.g. for use with categorical_crossentropy.\n",
    "    # Arguments\n",
    "        y: class vector to be converted into a matrix\n",
    "            (integers from 0 to num_classes).\n",
    "        num_classes: total number of classes.\n",
    "        dtype: The data type expected by the input, as a string\n",
    "            (`float32`, `float64`, `int32`...)\n",
    "    # Returns\n",
    "        A binary matrix representation of the input. The classes axis\n",
    "        is placed last.\n",
    "    # Example\n",
    "    ```python\n",
    "    # Consider an array of 5 labels out of a set of 3 classes {0, 1, 2}:\n",
    "    > labels\n",
    "    array([0, 2, 1, 2, 0])\n",
    "    # `to_categorical` converts this into a matrix with as many\n",
    "    # columns as there are classes. The number of rows\n",
    "    # stays the same.\n",
    "    > to_categorical(labels)\n",
    "    array([[ 1.,  0.,  0.],\n",
    "           [ 0.,  0.,  1.],\n",
    "           [ 0.,  1.,  0.],\n",
    "           [ 0.,  0.,  1.],\n",
    "           [ 1.,  0.,  0.]], dtype=float32)\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    y = np.array(y, dtype='int')\n",
    "    input_shape = y.shape\n",
    "    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n",
    "        input_shape = tuple(input_shape[:-1])\n",
    "    y = y.ravel()\n",
    "    if not num_classes:\n",
    "        num_classes = np.max(y) + 1\n",
    "    n = y.shape[0]\n",
    "    categorical = np.zeros((n, num_classes), dtype=dtype)\n",
    "    categorical[np.arange(n), y] = 1\n",
    "    output_shape = input_shape + (num_classes,)\n",
    "    categorical = np.reshape(categorical, output_shape)\n",
    "    return categorical\n",
    "\n",
    "# load the dataset, returns train and test X and y elements\n",
    "# prefix -> 'D:/vscode_workspace/PracticeLab/IMU/code/dataset/UCI HAR Dataset/'\n",
    "def load_dataset(prefix=''):\n",
    "    df = pd.read_csv(r'D:\\vscode_workspace\\PracticeLab\\IMU_concat2.txt', sep='\\t', header = 0)\n",
    "    df = df.sort_values(by = ['user'], ignore_index=True)\n",
    "    # train data -> Users upto User ID = 3 (i.e. 3 users)\n",
    "    df_train = df[df['user'] <= 3]\n",
    "    # test data -> Users ID = 4 (i.e. 1 users)\n",
    "    df_test = df[df['user'] > 3]\n",
    "    trainy = df_train.type\n",
    "    testy = df_test.type\n",
    "    trainX = df_train.drop(labels='type', axis=1)\n",
    "    testX = df_test.drop(labels='type', axis=1)\n",
    "    trainX = trainX.drop(labels='user', axis=1)\n",
    "    testX = testX.drop(labels='user', axis=1)\n",
    "\n",
    "    print('before dstack')\n",
    "    print(trainX.shape, trainy.shape)\n",
    "\n",
    "    # trainX = np.array(trainX)\n",
    "    # testX = np.array(testX)\n",
    "    trainX = np.array(trainX).reshape(trainX.shape[1], trainX.shape[0], 1)\n",
    "    testX = np.array(testX)\n",
    "\n",
    "    trainX = np.dstack(trainX)\n",
    "    trainy = np.dstack(trainy)\n",
    "    print('after dstack')\n",
    "    print(trainX.shape, trainy.shape)\n",
    "\n",
    "    # testX = np.dstack(testX)\n",
    "    # testy = np.dstack(testy)\n",
    "    testX = testX.reshape(testX.shape[0], -1)\n",
    "    testy = np.array(testy).reshape(testy.shape[0], -1)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    trainy = label_encoder.fit_transform(df_train.type)\n",
    "    testy = label_encoder.fit_transform(df_test.type)   \n",
    "    \n",
    "    # load all train\n",
    "    # trainX, trainy = load_dataset_group('train', prefix)\n",
    "    # print(trainX.shape, trainy.shape)\n",
    "    # load all test\n",
    "    # testX, testy = load_dataset_group('test', prefix)\n",
    "    # print(testX.shape, testy.shape)\n",
    "    # zero-offset class values\n",
    "    # trainy = trainy - 1\n",
    "    # testy = testy - 1\n",
    "    # one hot encode y\n",
    "    trainy = to_categorical(trainy)\n",
    "    testy = to_categorical(testy)\n",
    "    print('loading')\n",
    "    print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "    return trainX, trainy, testX, testy\n",
    "\n",
    "# load data set and split into training and testing inputs (X) and outputs (y)\n",
    "# trainX, trainy, testX, testy = load_dataset('D:/vscode_workspace/PracticeLab/IMU/code/dataset/UCI HAR Dataset/')\n",
    "trainX, trainy, testX, testy = load_dataset()\n",
    "print('after load:')\n",
    "print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "\n",
    "n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "\n",
    "# define the model using pytorch\n",
    "class ConvNet1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(n_features, 64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.MaxPool1d(10))\n",
    "        self.layer2 = nn.Flatten()\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(768,100),\n",
    "            nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "            # nn.Linear(100,6),\n",
    "            nn.Linear(100,4),\n",
    "            nn.Softmax())\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        return out\n",
    "\n",
    "model = ConvNet1D()\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "# total_step = len(trainX)\n",
    "total_step = trainX.shape[2]\n",
    "print(trainX.shape)\n",
    "\n",
    "# transformation of data into torch tensors\n",
    "trainXT = torch.from_numpy(trainX)\n",
    "trainXT = trainXT.transpose(1,2).float() #input is (N, Cin, Lin) = Ntimesteps, Nfeatures, 128\n",
    "trainyT = torch.from_numpy(trainy).float()\n",
    "testXT = torch.from_numpy(testX)\n",
    "testXT = testXT.transpose(1,2).float()\n",
    "testyT = torch.from_numpy(testy).float()\n",
    "num_epochs = 50\n",
    "batch_size = 98\n",
    "\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "acc_list_epoch = []\n",
    "for epoch in range(num_epochs):\n",
    "    correct_sum = 0\n",
    "    for i in range(int(np.floor(total_step/batch_size))): # split data into batches\n",
    "        trainXT_seg = trainXT[i*batch_size:(i+1)*batch_size]\n",
    "        trainyT_seg = trainyT[i*batch_size:(i+1)*batch_size]\n",
    "        # Run the forward pass\n",
    "        outputs = model(trainXT_seg)\n",
    "        loss = criterion(outputs, torch.max(trainyT_seg, 1)[1])\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        # Backprop and perform Adam optimisation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Track the accuracy\n",
    "        total = trainyT_seg.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        _, actual = torch.max(trainyT_seg, 1)\n",
    "        correct = (predicted == actual).sum().item()\n",
    "        correct_sum = correct_sum + (correct/total)\n",
    "        acc_list.append(correct / total)\n",
    "    print(\"Epoch\")\n",
    "    print(epoch)\n",
    "    print(\"accuracy\")\n",
    "    accuracy = correct_sum/int(np.floor(total_step/batch_size))\n",
    "    print(accuracy)\n",
    "    # print(correct_sum/int(np.floor(total_step/batch_size)))\n",
    "    acc_list_epoch.append(correct_sum/int(np.floor(total_step/batch_size)))\n",
    "    # acc_list_epoch.append(correct_sum/int(np.ceil(total_step/batch_size)))\n",
    "\n",
    "#plot the training accuracy\n",
    "plt.title('Training Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.grid(True)\n",
    "plt.autoscale(axis='x', tight=True)\n",
    "plt.plot(acc_list_epoch)\n",
    "plt.show()\n",
    "\n",
    "# Test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(testXT)\n",
    "    _, predictedt = torch.max(test_outputs, 1)\n",
    "    _, actual = torch.max(testyT, 1)\n",
    "    total_t = testyT.size(0)\n",
    "    correct_t = (predictedt == actual).sum().item()\n",
    "    print('Test accuracy:')\n",
    "    print((correct_t/total_t)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 2],\n",
       "        [2, 4],\n",
       "        [3, 5]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([[1, 2, 3], [2, 4, 5]])\n",
    "\n",
    "np.dstack(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### np.dstack\n",
    "按深度顺序堆叠arrays。当数组为2维数组(M,N)或1维数组(N,)时，</br>\n",
    "首先分别将其维度改变为(M,N,1)、(1,N,1)，然后沿着第三根轴(r/g/b通道)进行拼接。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1 3]\n",
      "  [2 4]]]\n",
      "-------------------------\n",
      "[[[1 4]\n",
      "  [1 4]]\n",
      "\n",
      " [[2 5]\n",
      "  [2 5]]\n",
      "\n",
      " [[3 6]\n",
      "  [3 6]]]\n",
      "(3, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "# 一维\n",
    "a = np.array([1, 2])\n",
    "b = np.array([3, 4])\n",
    "print(np.dstack((a,b)))\n",
    " \n",
    "# 二维\n",
    "a = np.array([[1, 1],\n",
    "              [2, 2],\n",
    "              [3, 3]])\n",
    "b = np.array([[4, 4],\n",
    "              [5, 5],\n",
    "              [6, 6]])\n",
    "print('-------------------------')\n",
    "print(np.dstack((a,b)))\n",
    "print(np.dstack((a,b)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### np.hstack()\n",
    "水平方向（列）顺序堆叠arrays。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n",
      "[[1 1 4 4]\n",
      " [2 2 5 5]\n",
      " [3 3 6 6]]\n",
      "(3, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    " \n",
    "# 一维\n",
    "a = np.array([1, 2])\n",
    "b = np.array([3, 4])\n",
    "print(np.hstack((a,b)))\n",
    " \n",
    "# 二维\n",
    "a = np.array([[1, 1],\n",
    "              [2, 2],\n",
    "              [3, 3]])\n",
    "b = np.array([[4, 4],\n",
    "              [5, 5],\n",
    "              [6, 6]])\n",
    "print(np.hstack((a,b)))\n",
    "print(np.hstack((a,b)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### np.vstack()\n",
    "垂直方向（行）顺序堆叠arrays。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "[[1 1]\n",
      " [2 2]\n",
      " [3 3]\n",
      " [4 4]\n",
      " [5 5]\n",
      " [6 6]]\n"
     ]
    }
   ],
   "source": [
    "# 一维\n",
    "a = np.array([1, 2])\n",
    "b = np.array([3, 4])\n",
    "print(np.vstack((a,b)))\n",
    " \n",
    "# 二维\n",
    "a = np.array([[1, 1],\n",
    "              [2, 2],\n",
    "              [3, 3]])\n",
    "b = np.array([[4, 4],\n",
    "              [5, 5],\n",
    "              [6, 6]])\n",
    "print(np.vstack((a,b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.floor(1/98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ceil(1/98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:(1003788, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"test:{}\".format(trainX.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe.shape:(7352, 128)\n",
      "dataframe.shape:(7352, 128)\n",
      "dataframe.shape:(7352, 128)\n",
      "dataframe.shape:(7352, 128)\n",
      "dataframe.shape:(7352, 128)\n",
      "dataframe.shape:(7352, 128)\n",
      "dataframe.shape:(7352, 128)\n",
      "dataframe.shape:(7352, 128)\n",
      "dataframe.shape:(7352, 128)\n",
      "load_group before dstack:(9, 7352, 128)\n",
      "load_group after dstack:(7352, 128, 9)\n",
      "dataframe.shape:(7352, 1)\n",
      "line 42, y:(7352, 1)\n",
      "line 91,after load_dataset_group train x,y shape:(7352, 128, 9),(7352, 1)\n",
      "dataframe.shape:(2947, 128)\n",
      "dataframe.shape:(2947, 128)\n",
      "dataframe.shape:(2947, 128)\n",
      "dataframe.shape:(2947, 128)\n",
      "dataframe.shape:(2947, 128)\n",
      "dataframe.shape:(2947, 128)\n",
      "dataframe.shape:(2947, 128)\n",
      "dataframe.shape:(2947, 128)\n",
      "dataframe.shape:(2947, 128)\n",
      "load_group before dstack:(9, 2947, 128)\n",
      "load_group after dstack:(2947, 128, 9)\n",
      "dataframe.shape:(2947, 1)\n",
      "line 42, y:(2947, 1)\n",
      "line 94,after load_dataset_group test x,y shape:(2947, 128, 9),(2947, 1)\n",
      "(7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "after load_dataset, shape of all: (7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n",
      "shape of all: (7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n",
      "trainXT.shape: torch.Size([7352, 9, 128]), trainyT.shape: torch.Size([7352, 6]), testXT.shape:torch.Size([2947, 9, 128]), testyT.shape:torch.Size([2947, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\lib\\site-packages\\torch\\nn\\modules\\container.py:204: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "accuracy: 0.6027565502183406\n",
      "Epoch: 1\n",
      "accuracy: 0.767603711790393\n",
      "Epoch: 2\n",
      "accuracy: 0.8388373362445415\n",
      "Epoch: 3\n",
      "accuracy: 0.8751364628820961\n",
      "Epoch: 4\n",
      "accuracy: 0.9055676855895196\n",
      "Epoch: 5\n",
      "accuracy: 0.9059770742358079\n",
      "Epoch: 6\n",
      "accuracy: 0.9245360262008734\n",
      "Epoch: 7\n",
      "accuracy: 0.9358624454148472\n",
      "Epoch: 8\n",
      "accuracy: 0.9429585152838428\n",
      "Epoch: 9\n",
      "accuracy: 0.9425491266375546\n",
      "Epoch: 10\n",
      "accuracy: 0.9001091703056768\n",
      "Epoch: 11\n",
      "accuracy: 0.9455513100436681\n",
      "Epoch: 12\n",
      "accuracy: 0.9463700873362445\n",
      "Epoch: 13\n",
      "accuracy: 0.9496451965065502\n",
      "Epoch: 14\n",
      "accuracy: 0.9531932314410481\n",
      "Epoch: 15\n",
      "accuracy: 0.9542849344978166\n",
      "Epoch: 16\n",
      "accuracy: 0.9537390829694323\n",
      "Epoch: 17\n",
      "accuracy: 0.9531932314410481\n",
      "Epoch: 18\n",
      "accuracy: 0.9515556768558951\n",
      "Epoch: 19\n",
      "accuracy: 0.9552401746724891\n",
      "Epoch: 20\n",
      "accuracy: 0.863400655021834\n",
      "Epoch: 21\n",
      "accuracy: 0.9072052401746725\n",
      "Epoch: 22\n",
      "accuracy: 0.9480076419213974\n",
      "Epoch: 23\n",
      "accuracy: 0.9443231441048034\n",
      "Epoch: 24\n",
      "accuracy: 0.9516921397379913\n",
      "Epoch: 25\n",
      "accuracy: 0.9493722707423581\n",
      "Epoch: 26\n",
      "accuracy: 0.9514192139737991\n",
      "Epoch: 27\n",
      "accuracy: 0.9441866812227074\n",
      "Epoch: 28\n",
      "accuracy: 0.9544213973799127\n",
      "Epoch: 29\n",
      "accuracy: 0.9529203056768559\n",
      "Epoch: 30\n",
      "accuracy: 0.9536026200873362\n",
      "Epoch: 31\n",
      "accuracy: 0.9527838427947598\n",
      "Epoch: 32\n",
      "accuracy: 0.9540120087336245\n",
      "Epoch: 33\n",
      "accuracy: 0.9553766375545851\n",
      "Epoch: 34\n",
      "accuracy: 0.9499181222707423\n",
      "Epoch: 35\n",
      "accuracy: 0.9555131004366813\n",
      "Epoch: 36\n",
      "accuracy: 0.9541484716157205\n",
      "Epoch: 37\n",
      "accuracy: 0.9485534934497817\n",
      "Epoch: 38\n",
      "accuracy: 0.9510098253275109\n",
      "Epoch: 39\n",
      "accuracy: 0.9527838427947598\n",
      "Epoch: 40\n",
      "accuracy: 0.957150655021834\n",
      "Epoch: 41\n",
      "accuracy: 0.9477347161572053\n",
      "Epoch: 42\n",
      "accuracy: 0.9534661572052402\n",
      "Epoch: 43\n",
      "accuracy: 0.9545578602620087\n",
      "Epoch: 44\n",
      "accuracy: 0.957150655021834\n",
      "Epoch: 45\n",
      "accuracy: 0.9560589519650655\n",
      "Epoch: 46\n",
      "accuracy: 0.9576965065502183\n",
      "Epoch: 47\n",
      "accuracy: 0.9563318777292577\n",
      "Epoch: 48\n",
      "accuracy: 0.9561954148471615\n",
      "Epoch: 49\n",
      "accuracy: 0.9575600436681223\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABkQ0lEQVR4nO3deXhTZcI28DtJszTd943ShaXsRYHWCopISwVFQR0RF7AqKFJF+zkqyiI6Y8dlGF6VgdEBVxAGRlEU0VoWB2UTBGSnFCh0L6VNm7ZJmpzvjzSB0DWl7Uma+3ddvWhOzjl9kqfLzbNKBEEQQERERORCpGIXgIiIiKirMQARERGRy2EAIiIiIpfDAEREREQuhwGIiIiIXA4DEBEREbkcBiAiIiJyOQxARERE5HIYgIiIiMjlMAARUbs88sgjiI6Obte1r776KiQSSccWiIjIDgxARN2MRCJp08e2bdvELqro7rvvPkgkErz44otiF4WIupiEe4ERdS+ff/65zeNPP/0UWVlZ+Oyzz2yOp6SkICQkpN1fx2AwwGQyQalU2n1tfX096uvroVKp2v31r5VGo0FISAhCQ0NhNBpx7tw5tkoRuRAGIKJuLj09HUuXLkVrP+o1NTVQq9VdVCrxffTRR3jiiSfwww8/4NZbb8W2bdswevRosYvViCAIqKurg7u7u9hFIepW2AVG5IJuueUWDBo0CPv27cPNN98MtVqNl19+GQDw9ddf4/bbb0d4eDiUSiV69eqF119/HUaj0eYeV48BOnv2LCQSCd555x188MEH6NWrF5RKJUaMGIG9e/faXNvUGCCJRIL09HRs2LABgwYNglKpxMCBA7F58+ZG5d+2bRuGDx8OlUqFXr164V//+pfd44pWrVqFlJQUjBkzBv3798eqVauaPO/48eO47777EBQUBHd3d8TFxeGVV16xOSc/Px+PPfaY9T2LiYnBrFmzoNfrm329APDxxx9DIpHg7Nmz1mPR0dG444478MMPP2D48OFwd3fHv/71LwDm0HbrrbciODgYSqUSAwYMwLJly5os9/fff4/Ro0fDy8sL3t7eGDFiBFavXg0AWLhwIeRyOUpLSxtdN3PmTPj6+qKurq71N5HIibmJXQAiEsfFixcxfvx43H///XjooYes3WEff/wxPD09kZGRAU9PT2zZsgULFiyARqPB22+/3ep9V69ejaqqKjzxxBOQSCR46623cPfddyM3NxdyubzFa3fs2IEvv/wSTz31FLy8vPDuu+/innvuQV5eHgICAgAAv//+O2677TaEhYVh0aJFMBqNeO211xAUFNTm115QUICtW7fik08+AQBMnToV//jHP/D+++9DoVBYzzt06BBuuukmyOVyzJw5E9HR0Th9+jQ2btyIv/71r9Z7JSQkoKKiAjNnzkS/fv2Qn5+P9evXo6amxuZ+bXXixAlMnToVTzzxBGbMmIG4uDgAwLJlyzBw4EDceeedcHNzw8aNG/HUU0/BZDJh9uzZ1us//vhjPProoxg4cCDmzp0LX19f/P7779i8eTMeeOABPPzww3jttdewdu1apKenW6/T6/VYv3497rnnHlG7J4m6hEBE3drs2bOFq3/UR48eLQAQli9f3uj8mpqaRseeeOIJQa1WC3V1ddZj06dPF6KioqyPz5w5IwAQAgIChPLycuvxr7/+WgAgbNy40Xps4cKFjcoEQFAoFEJOTo712MGDBwUAwnvvvWc9NnHiREGtVgv5+fnWY6dOnRLc3Nwa3bM577zzjuDu7i5oNBpBEATh5MmTAgDhq6++sjnv5ptvFry8vIRz587ZHDeZTNbPp02bJkilUmHv3r2Nvo7lvKZeryAIwkcffSQAEM6cOWM9FhUVJQAQNm/e3Oj8puomNTVViI2NtT6uqKgQvLy8hMTERKG2trbZciclJQmJiYk2z3/55ZcCAGHr1q2Nvg5Rd8MuMCIXpVQqkZaW1uj4lWNNqqqqUFZWhptuugk1NTU4fvx4q/edMmUK/Pz8rI9vuukmAEBubm6r1yYnJ6NXr17Wx0OGDIG3t7f1WqPRiJ9++gmTJk1CeHi49bzevXtj/Pjxrd7fYtWqVbj99tvh5eUFAOjTpw+GDRtm0w1WWlqKn3/+GY8++ih69uxpc72lO8tkMmHDhg2YOHEihg8f3ujrtHdQdUxMDFJTUxsdv7JuKisrUVZWhtGjRyM3NxeVlZUAgKysLFRVVeGll15q1IpzZXmmTZuG3bt34/Tp09Zjq1atQmRkpEOOhSLqaAxARC4qIiKiye6ZI0eOYPLkyfDx8YG3tzeCgoLw0EMPAYD1j2xLrg4LljB06dIlu6+1XG+5tqSkBLW1tejdu3ej85o61pRjx47h999/x8iRI5GTk2P9uOWWW/Dtt99Co9EAuBzYBg0a1Oy9SktLodFoWjynPWJiYpo8/ssvvyA5ORkeHh7w9fVFUFCQdeyWpW4sgaa1Mk2ZMgVKpdIa+iorK/Htt9/iwQcf5Gw4cgkMQEQuqqlZRRUVFRg9ejQOHjyI1157DRs3bkRWVhbefPNNAOYWj9bIZLImjwttmHB6Lde2lWWZgOeeew59+vSxfvz9739HXV0d/vvf/3bY17JoLlBcPbDcoqm6OX36NMaOHYuysjIsXrwY3333HbKysvDcc88BaFvdXMnPzw933HGHNQCtX78eOp3OGnaJujsOgiYiq23btuHixYv48ssvcfPNN1uPnzlzRsRSXRYcHAyVSoWcnJxGzzV17GqCIGD16tUYM2YMnnrqqUbPv/7661i1ahXS0tIQGxsLADh8+HCz9wsKCoK3t3eL5wCXW8EqKirg6+trPX7u3LlWy2yxceNG6HQ6fPPNNzYtZVu3brU5z9KFePjw4VZbxaZNm4a77roLe/fuxapVq3Dddddh4MCBbS4TkTNjCxARWVlaYK5scdHr9fjnP/8pVpFsyGQyJCcnY8OGDSgoKLAez8nJwffff9/q9b/88gvOnj2LtLQ03HvvvY0+pkyZgq1bt6KgoABBQUG4+eabsXLlSuTl5dncx/L+SKVSTJo0CRs3bsRvv/3W6OtZzrOEkp9//tn6nFartc5Ca+trv/KegLnb6qOPPrI5b9y4cfDy8kJmZmajqexXt6SNHz8egYGBePPNN7F9+3a2/pBLYQsQEVndeOON8PPzw/Tp0/HMM89AIpHgs88+69AuqGv16quv4scff8TIkSMxa9YsGI1GvP/++xg0aBAOHDjQ4rWrVq2CTCbD7bff3uTzd955J1555RWsWbMGGRkZePfddzFq1Chcf/31mDlzJmJiYnD27Fl899131q/1xhtv4Mcff8To0aMxc+ZM9O/fH4WFhVi3bh127NgBX19fjBs3Dj179sRjjz2GP//5z5DJZFi5ciWCgoIahavmjBs3DgqFAhMnTsQTTzyB6upqfPjhhwgODkZhYaH1PG9vb/zjH//A448/jhEjRuCBBx6An58fDh48iJqaGpvQJZfLcf/99+P999+HTCbD1KlT21QWou6ALUBEZBUQEIBvv/0WYWFhmDdvHt555x2kpKTgrbfeErtoVsOGDcP3338PPz8/zJ8/HytWrMBrr72GsWPHtrh2jcFgwLp163DjjTfC39+/yXMGDRqEmJgY6zih+Ph47Nq1CzfffDOWLVuGZ555Bv/9739x5513Wq+JiIjA7t27ce+992LVqlV45pln8Omnn+KWW26xrqwtl8vx1VdfoVevXpg/fz7effddPP744zZr8LQmLi4O69evh0QiwfPPP4/ly5dj5syZmDNnTqNzH3vsMXzzzTfw9vbG66+/jhdffBH79+9vcqbctGnTAABjx45FWFhYm8tD5Oy4FQYRdQuTJk3CkSNHcOrUKbGL4lQOHjyIoUOH4tNPP8XDDz8sdnGIugxbgIjI6dTW1to8PnXqFDZt2oRbbrlFnAI5sQ8//BCenp64++67xS4KUZfiGCAicjqxsbF45JFHEBsbi3PnzmHZsmVQKBR44YUXxC6a09i4cSOOHj2KDz74AOnp6fDw8BC7SERdil1gROR00tLSsHXrVhQVFUGpVCIpKQlvvPEGrr/+erGL5jSio6NRXFyM1NRUfPbZZ9ZVsYlcBQMQERERuRyOASIiIiKXwwBERERELoeDoJtgMplQUFAALy8vbgpIRETkJARBQFVVFcLDwyGVttzGwwDUhIKCAkRGRopdDCIiImqH8+fPo0ePHi2ewwDUBMtsiDNnzjS7Yix1LYPBgB9//BHjxo2DXC4XuzgE1omjYr04HtZJ19FoNIiMjGzTrEYGoCZYur28vLzg7e0tcmkIMP8CUavV8Pb25i8QB8E6cUysF8fDOul6bRm+wkHQRERE5HIYgIiIiMjlMAARERGRy2EAIiIiIpfDAEREREQuhwGIiIiIXA4DEBEREbkcBiAiIiJyOQxARERE5HIYgIiIiMjlMAARERGRy2EAIiIiIpfDAEREREQdRhAElFbpUGcwil2UFnE3eCIiok5y4VIN1v92HqWlEkwQuzBXMZkEnCqpxp4zF3GqpBp+agVCvFUI8VY2/KtCgIcCUmnTO6vX6OuRW6rF6dJq5JZqkVumRW7D57UN4SfEW4lIPzV6+Lkj0r/hXz81evipEearglxmfztMjb4eFy7V4nx5Dc6X15g/v1SD8+W1OFdU2ub7MAAREZFDqjea4NaOP5BiM5oEbD9Zgs935WHriRIIAgDI4LbpOBZMHARZM4Gis9UbTThaqMGeM+XYfaYce8+Wo6LG0OI1blIJgryUCPZWIcRLCV+1HPkVtcgt1aKwsq7Vr1ms0aFYo8Nv5y41ek4qAcJ83OGpdINMKoFMKoFUKoFMArhJpZBK0XBcCpkEKK8x4EJ5DS5q9c1+PZOu7a1ODEBEBMDcbP37+QpsPFiAwoo6vHH3YPh7KMQuVrcnCAIkEnH+INrL0rVx/lItLlyy/d/3hUu18FUr8OTNsUgdGNpsq0Fb7DlTjnd+OIE9Z8sR6KlAhJ8akX7u6OGnRqS/u7VFIcLPHUo3WQe+wmtTWqXDf347j9W785BfUWs9PiTCG4fyNfhkZx6KNXosuX8oVPLOLbcgCKioMSCntNoaePadLYdWbxsQ3OUyDIvyw8AIb1TV1aNEU9cQWupQWq1DvUlAYWVds2HH30OB2EAPxAZ5oFeQJ2KDPBEb5IGe/mpU1dVf1UJj+/2irzfZvE/28Fa52bQoWT73k9dj2JK23YMBiKiD1ejrrb9ALn+YH5dodCipqoMAwEPhBk+lGzyUMngoLZ+7NXx+xTGF2xXPy6znqRWya/7DKQgCjhVW4ZuDBfj2UAEuXLr8yygx1h9pI2Ou8d2g5giCgPe25ODDn3PhpXJDVIAHogPV5n8DzP9GBaihVrT8a1oQBNQajKisNUBTW49L1bW4oAUKK+sQ7CO16w+tvt6Eoso6FFTWorCyFgUVdSioqLX+0cq/VAtdvanZ689drMGsVfsxIMwbGSl9MbZ/sF3fo39cqMQ7P57A9pOXuzHKqvUoq9bj4PmKRudLJECwlxIxgR546IYoTBgUdk3Bqz0EQcCu3HJ8vvscfjxSBINRAAD4uMtx77AeeCCxJ3r6KvGXT7/H6lw3bD5ShAf/vRsfThve7v9g1BtNOHuxxhxWqsy/X4oq61BSZfu7Rm9sXFdeKjckRPsjIcb8MSjCp9luqHqjCWXV+su/x6p0KK/WI8xXhV5BHogN9IRfC6/B30MBfw8F4iN9Gz1nMgkoqzaH6TqDEfUmASaTAKNJMH8umD+/8sPbXY5If3MQ9nGXN/k1NRpN295EOEAAWrp0Kd5++20UFRUhPj4e7733HhISEpo812AwIDMzE5988gny8/MRFxeHN998E7fddpv1nFdffRWLFi2yuS4uLg7Hjx/v1NdBrkkQBJwsrsZ3fxTip6PFOF9egypdfZd8bYkEDeFIhgAPJWKDPBAb5Gn9xRQb5AEPZdM/4qdLq7HxYAE2HizA6VKt9biHQgY/DwUuXKpFQTv/Z0atEwQBf/nuGFbsOAMAqNLVo6CyDjtzLzY6N8hLiegA85gJvdEETa3B/FFX3xB6DKg3CVdd5Ya3D/0MAFDJpfBXK+DnoYBfw7/+ajl81ApodfUoqKhFQaU56JRV6xq6a5pn6bbocVWLTISfO37NKcPKX87iaKEGj3/6G+J7+OC5lL4Y3TeoxSCUU1KFv/94Et8fLjKXXirB/QmReGxULGr09Thfbm5xso77aBjvUWswWrtYduWWY0DYafw5NQ63xLX89a6FIAgo1uhwqqQKh/M1WL/vvM3P0HU9ffFQYhRuHxJmDZ8GgwHXBwpIuWkYnlp9APvOXcK9y37Fx2kJ6BmgbvPXNpoEfH0gH3//8WSbW06CvJQYHuVnDTz9Qr3b3AXnJpMi1EeFUB9Vm8vYVlKpBMHeKgR7d/y920rUALR27VpkZGRg+fLlSExMxJIlS5CamooTJ04gODi40fnz5s3D559/jg8//BD9+vXDDz/8gMmTJ+PXX3/FddddZz1v4MCB+Omnn6yP3dxEz3nUjQiCgBPFVdh0qBDf/VFo88vPQq2QIdRbhWBvJUIbBhMGNwwuDPZSQSYFqnVGaHX1qNbVQ9vwUWX93GhzvLrhmFZXj2p9PQQBEASguuG5Yo0ORwsb/88n1FvVEIzMoUhXb8K3hwpwpODyuQo3Kcb2C8bE+HCMiQvGF3vy8Nq3R1FQ0Xr/vqPbnXsRpdU6xPfwRQ8/92v+o1jZMF7CR930/z7bwmQSMP/rw1i1Ow8AMO/2/rg+yg/nLmpxtqzG/O9F87+XagwordKhtEqHvWcbj6G4kkwqgY+7HB4KGSqra1BjlKLeJKDOYDIHnDaM1wDM3w/hPiqE+7ojzMcd4b4qRPiaB7BGtjJw9YbYAKSNjMEH/8vFx7+cxcELlXjko70YFuWH/5fSFzf2DrQ5/3x5DZb8dApf/X4BJsEc6icPjcCzyX1tgsHAcJ9GX0sQBJRr9Th/qRbbT5Ti3//LxdFCDdI+Nn+9P6fG4YbYgDa95qYIgoAiTR1OFVfjZHEVckrM/54qqUZVne1/ctQKGSZdF4EHE3s2WVaLxBh//HfWjXjko73ILdPi7mW/YMX0EU22kFxdlq0nSvDW5hM4XlRl/Zrhvu7mActe5t8voQ2Dly2/a4K8lA7VRehoJILQWt7vPImJiRgxYgTef/99AIDJZEJkZCSefvppvPTSS43ODw8PxyuvvILZs2dbj91zzz1wd3fH559/DsDcArRhwwYcOHCg3eXSaDTw8fFBWVkZAgLa/wNEHcdgMGDTpk2YMGEC5PL2//FpL0tX0aY/CrHpcCFyrwg9CpkUN/cNxITBYYiP9EWItwqezbS8dFRZag1Gm1BUVFmH3LKGmRilWuSWVaOsuvmBgm5SCW7qE4iJ8eFIGRACL9Xl93Tz4UI8+fl+DI30xYbZI5u9h9h10pKKGj0WfH0E3xwssB4L9FRgaKQvruvph6GRvhjSw8fmdV/J8sfvSL4GRwo0OFJQiSMFGuRX1EIqAZ4Y3QvPJvex+49LvdGEF9Yfwpe/50MiAd68ewjuGxHZ7PmVNQacKzcHovxLtVDJpfBxl8NbJYe3u9z8ubsbvFVya5eopV7Gjx+POpMEFVoDymv0uFSjxyWtHuVaPSpqzMc8lW4Iawg74T7uCPM1z/rpiNaTsmodlm87jc92nbN2m90Q64+MlDhEB6jx/tYcfLEnz9pllDowBBkpcYgL9WrX17uk1WP5z6fx8S9nrV/vpj6B+HNqHIb08G31+tIqHfadu4R958qxP68CJ4uqmm3NlUkliApQo0+wJ0b1CcKkoeHNfi8BjX9WijV1SPtoL44WauAul+H9B67D2P4hTV67P+8S/vb9cew5Uw7APPZl1i298ciN0XBXMNxczfL3u7KyEt7e3i2eK1rTiF6vx759+zB37lzrMalUiuTkZOzcubPJa3Q6HVQq2+Yyd3d37Nixw+bYqVOnEB4eDpVKhaSkJGRmZqJnz57NlkWn00Gn01kfW/oQDQYDDIaWR8hT17DUQ1fWh8kk4HCBBj8dK8H3R4px9mKN9TmFmxQ39Q7A+IEhuLVf0FW//IROL6dcAvipZPBTyQAoEBesxug+/jbnVNYakFumxZkyLc6U1SC3TAt9vQlj+wUjdWAw/NSX++6vLG+wp/m1FFTUtvg6xKiTtvjfqTLM/eoIiqt0kEkliAvxxKkScyD86VgJfjpWAsDc2tA7yAPxPXwxNNIHHgoZjhZW4WhhFY4VaVCubfp1mQRg2bbTyD5ajLfuGYSB4S3/krXQ15vw/9b/gc1HiiGTSvD2PYMwcUhoi++fWg70D/FA/xCPVu4uoL7e/Mfacr/6+nq4y+Vw95YjzFsOoLV7wHpdR/BRSvFiah88khSJf/3vLNbsPY9dueW47187IZdJrMFnZK8AZCT3xpAePjblt5enQoLnk3vj4YQeWLb9DNb+dgH/O1WG/50qw7gBwXh2bG/0CfYEYP7Zzimtxv68SuzPu4R9eRXIK2/cpSSTShDlr0afYA/0DvZEn2BP9A7yQHSgB5Rutq1g9vys+LvLsOqx4XhmzUH8L+ciZnz6G16d2B9TrwjDOSXVWPxTDrIavl+VblI8fENPPHFTDHzVcgAmGAzNj8dyVfZ8/4jWAlRQUICIiAj8+uuvSEpKsh5/4YUXsH37duzevbvRNQ888AAOHjyIDRs2oFevXsjOzsZdd90Fo9FoDTDff/89qqurERcXh8LCQixatAj5+fk4fPgwvLya/p9FU+OGAGD16tVQq9veP0vOz2ACTlZKcPiSBEfKJag0XP6fsJtEQH9fAUMDBAzyE6Dqpj2rVQZg3m9ukEDAO4lGuDnJLGSdEfjmnBQ7is0FDlYJeKi3EVFe5nrN1wJnqyU4WyXBuWoJynUtt3JIISDEHejhISDCQ0APDyDCQ8CpSgn+kytFdb0EUomAcREmjIsQ0NJsbYMJWHlCiqMVUsgkAh7pa8IQf9Ea30VxSQf8mC/FrhIJTIIE0Z4C7uhpQh+fznkfyuqAzRek+K1UAgESSCAgPkCAzgicrZKg1mhb/xIICFUDsV4CYrzMdR6sQqd+/xtNwNpcKXaXmr9ISoQJI0NM2HxBit0ll8udGCxgfA8TfJWdV5buoqamBg888ECbWoCcKgCVlpZixowZ2LhxIyQSCXr16oXk5GSsXLkStbVNDwirqKhAVFQUFi9ejMcee6zJc5pqAYqMjERhYSG7wByEwWBAVlYWUlJSOry7pVyrx7aTpcg+XoodORdRc8U0UQ+FDKN6ByB1YAjGxAV1ateWoxAEAYNey4a+3oQtGaMQ6df0fwI6uk6KNHWY8el++KrluH1wWKNWqpb8fr4Cf15/GOfKza10027oiedT+rTYRVBWrcPB85U4cKESBy9Uos5gRL9QLwwI88aAMC/0DfFsdgbVRa0eC785ih+Omv93PjDcC2/dPQh9Qxr/J6tGX49Zqw7g19xyKN2kWPbAUNzUJ7DReR2lM39WOkJBRS0KK+twfU/fLpn+f6q4Gku25ODHhrqycJdLEd/DB9f39MOwKF8M7eED72ZmFl2rlupEEAS8vzUX7249DcA8yNwypj2lfzAyknujd0PLFbVOo9EgMDDQsbvAAgMDIZPJUFxcbHO8uLgYoaGhTV4TFBSEDRs2oK6uDhcvXkR4eDheeuklxMbGNvt1fH190bdvX+Tk5DR7jlKphFLZOFrL5XKH/AXiytpbJ/p6Eypq9OaxEFoDLtXokVdegy3HSvDbuXJcOYkm1FuF5AHBSO4fgqReAS45iDDC1x1nyrQoqa5HbHDL73dH/Zx8+0cejhdXAwB2nbmERd8ea3ackoW+3oR3s0/hn9tyYBKAMB8V3r43HqPaEDDC/OQI8/PEbUMi7C5rqK8cyx8ejm8OFmDB10dwpKAKk5ftxnMpfTHz5ljrLBtNnQGPffo7fjt3CR4KGVY8MuKaBubaw1F/f0UFyREV1LZuw44woIcfPpg2AgfPV+DbQwUI93XH8Ch/9A/z6vJFFpurk4zUfujh74G5X/0Bo0lAQow/XrytH4ZF+XVp+boDe77nRQtACoUCw4YNQ3Z2NiZNmgTAPAg6Ozsb6enpLV6rUqkQEREBg8GA//73v7jvvvuaPbe6uhqnT5/Gww8/3JHFJwd1vEiDD38+g7JqnXnQZ0PgqW5lanr/MG+kDAhBSv8QDIrwdpqF6TpLmI8KZ8q0XToV/tfTZQCAMXFB1lltW0+UYuuJUijcpLg1Lhh3Dg3Hrf2CoZLLcLK4Cs+tPWCd0Tb5ugi8eufAZtcH6WgSiQR3DY1AUmwA5n75B7KPl+DNzcfx49Ei/P1P8fD3UGDayj04dKES3io3fPxoAq7vyT9oYomP9G11tpWY7hsRiYER3qiuq0dCjL/L/w7qCqK252dkZGD69OkYPnw4EhISsGTJEmi1WqSlpQEApk2bhoiICGRmZgIAdu/ejfz8fAwdOhT5+fl49dVXYTKZ8MILL1jv+fzzz2PixImIiopCQUEBFi5cCJlMhqlTp4ryGqlr/e3749h2oum9YKQSwFetgJ9aDj+1AgGeCiTFBiB5QAh6NNPN46rCfd0BoMsCkK7eiL1nzbNc5k7oj74hXsgpqca3hwrwzcEC5JZqsflIETYfKYKHQoakXoH4+VQp9PUm+Knl+OvkwZgwOKxLynq1YG8V/j19ONbtu4DXNx7F73kVGP9//0OojwrnLtbA30OBTx9NwKCI5qdHEwFNT/enziNqAJoyZQpKS0uxYMECFBUVYejQodi8eTNCQszTAfPy8iCVXm6irKurw7x585CbmwtPT09MmDABn332GXx9fa3nXLhwAVOnTsXFixcRFBSEUaNGYdeuXQgKCurql+fStLp6FGnq4C6XQSWXwV0ug9JN2qmrtBpNAn5rWCvlpfH90DvIs2HxNzn8PRTwVsm7fJVYZ2UJQPldtBbQ/nMVqDOYEOSltM7U6R3siWeT+2LO2D7W1ao3HixAfkUtfjpm7jq/tV8w/nb3YFEXUwPMrUH3DY/EqN6BePG/h/C/U2U4d7EGwV5KrHo8EX2aGBtEROISfURnenp6s11e27Zts3k8evRoHD16tMX7rVmzpqOKRu0gCALW/XYBr397tMk1NFRyqU0oUsll6B/mjTfvGXzN/fHHizSo1tXDU+mGGTfFirbhYHcQ4WsOFIWVXdMCZOn+urFXQKOmf4lEggHh3hgQ7o0Xb4vD7+cr8MORIvQN9sLd10c4VFdBuK87Pn00AWv2nsevpy/i/6X0RXRg26afE1HXEj0AUfdRUFGLl778Az837OOjVshQbxKgv2LvoDqDCXUGE4DLazUcLdRg8nURbRq42pK9DQuFXR/lx/Bzjbq6C+yXHHMAGtmr5e8BiUSC63v6OfRYGolEgqkJPTE1ofm1x4hIfAxAdM0EQcDavefxl++OoVpXD4WbFP8vpS8eGxUDN5kURpOAOoMRtQYjavVGm8+XbT+NbSdKsSv34rUHoHPm7q8RnDlxzaxdYJdqO3238qo6Aw5eqAQA3Niby04QUddgAKJrkl9Ri5caxjwA5o0A37433mbdCplUYt3l/GpnL2qx7URpk5tA2kMQBPzWMIh2eLR/K2dTa8J9zAFIqzdCU1ffqTOrdueWw2gSENWw4ScRUVdgAKJ2EQQBX+w5jzc2mVt9lG5SPD8uDo+OirGr+ykp1tzqc/B8BWr09VAr2vcteeFSLYo1OshlEgx14KmuzsJdIYOfWo5LNQYUVNR2agD6xTr+p/MWByQiuhoDENntfHkN5n75B3Y0jNsYFuWHt+4dgl5B9q9WGunvjnAfFQoq6/Db2Uu4uW/7ZutZplAPivDhBoEdJNzXHZdqDCisrEX/sM5buO7XHHPr30h2fxFRF3KSXX7IUazenYfblvyMHTllUMmlmH/HAPzniaR2hR/APGD0hl7mP3y7rqEbzBKARrD7q8N0xVT40iodThRXAWALEBF1LbYAUZst23Yab24+DgAYEe2Ht+6NR0wHTPG9ITYAX+7Pv6ZxQHsb1v8ZzgHQHSaiC2aCWaa/Dwjzhr9H2/b9IiLqCAxA1Caf7TxrDT/PJvfBM7f26bBFBZMa9kY6dKESWl19k4OlW1Ku1SOnxLyHFAdAd5wwH/NaQJ0agNj9RUQiYRcYterL/Rcw/+sjAICnb+2NZ5P7duiKypH+akT4usNoEqxdWfbY1zD9vXewJ1sROlBXrAVkHQDdm91fRNS1GICoRZsPF+HP6w8BAB65MRoZKX075eskWccB2R+ALo//YfdXR7ocgDpnDFDexRpcuFQLN6kECWy5I6IuxgBEzfrfqVI888XvMJoE3DusBxbcMaDTFsS7oaEbrD3jgCwBaHgU/4h2JMsYoCJNHYwmocPvb2n9ua6nr93dnkRE14oBiJr029lyzPx0H/RGEyYMDsXf7h7cqRuJWlqADudXoqrO0MrZl9XqjTicb15FOCGGAagjBXkp4SaVwGgSUFLV8a1Alu0vOPuLiMTAAESNHM6vRNpHe1FrMGJ03yAsmXLdNW9U2poIX3f09Ffb7OjeFgcvVMBgFBDirUQPP/dOLKHrkUklCPHunIHQJpOAnactA6AZgIio6zEAkY2ckipMW7kHVbp6JET7Y/lDw6Bw65pvkxtizS049qwHdOX2F460K3h3EdFJawEdL6rCRa0e7nIZV+4mIlEwAJHV+fIaPPjv3SjX6jGkhw9WPDK8S1dVtnSD2TMOaM9ZboDamcJ9zS1AhR3cAmRZ/ychxr/LAjYR0ZX4m4cAAMWaOjz4790o1ujQJ9gTn6QlwEvVefs/NcUyEPpwfiU0bRgHZDQJ2G/ZAZ7jfzpFZ02Ft4z/4fo/RCQWBiCCps6Ah/69G3nlNejpr8bnjyfCT4T1dMJ83BEdoIZJAPaeaX06/PEiDap19fBUuqFfaOftVeXKOmM7DIPRhD0N9cvxP0QkFgYgwrs/ncKpkmqEeCux6vFE68BXMVhagdoyDsgyWPr6KD+7dqCntrN0gXVkC9DB8xXQ6o3w91CgP4MrEYmEAcjFnS6txse/ngUAvHnPEET6q0Utjz3jgPZYFkDk+J9OY+0Cq+y4APRLw/YXSbEBnbq0AhFRSxiAXNxfvzuGepOAW/sF45a4YLGLY20BOlKgQWVt8+OABEGwzgDj+J/OYwlAFTUG1OjrO+Sel7e/4PgfIhIPA5AL23aiBFuOl8BNKsErt/cXuzgAgBBvFWIDPSAIsI4TacqFS7Uo1uggl0kQ38O36wroYrxVcng1rNLcEVti1Ojr8XueuetyJBdAJCIRMQC5KIPRhNe/PQrAvMdXryBPkUt0WWIbxgFZtr8YFOHTpVP1XVFHzgTbe/YSDEYBEb7uiAoQt7uViFwbA5CL+mznOZwu1cLfQ4Gnx/YRuzg2rOOATrcUgBqmv3MTzU4X1oEDoX+1bn8RwIUriUhUDEAuqFyrx5KfTgIAnh8XBx/3rl3vpzU3NIzpOVakQUWNvslzLu8AzwDU2TqyBcgy/ofT34lIbAxALmhx1glo6urRP8wbU0ZEil2cRoK9VegVZB4HtLuJcUDlWj1ySqoBAMM4A6zTRVhngl3bGKBLWj2OFGgAmFuAiIjExADkYo4XabB6dx4AYMEdAxx2/ZyW1gPa17D6c+9gT/iLsGCjq+motYB25l6EIAB9gj0RLOJaU0REAAOQSxEEAa9tPAqTAIwfFGoda+OIWhoHZJ3+Hs3Wn64Q7tMxXWCXt79g9xcRiY8ByIX8eLQYv56+CIWbFC9PcIxp781JjDEHoONFVbiktR0HtIfjf7pU+BVdYCaT0O77/NoQZhmAiMgRMAC5CF29EX/97hgAYMZNMaKv+NyaIC8l+gSbp+bvPnO5FahWb8Th/EoADEBdJcRbBYkE0NebcFHb9KD01hRU1OJMmRZSCZAYy3ojIvExALmIlTvOIq+8BsFeSjx1S2+xi9Mml8cBXR4IfSi/EgajgBBvJXr4uYtVNJeicJMi2EsJAChs55YYlu6vIT184a1yrFmHROSaGIBcQImmDu9vOQUAePG2fvBoWNnX0TU1DmjfuQoAwPBof64j04WudSr85e4vxx13RkSuhQHIBbz9wwlo9UbER/pi8nURYhenzRIb1gM6UVxl7XrZ17CNQgK7v7qUJQDlt2M7DEEQLg+A5vYXROQgGIC6uUMXKrBu3wUAwMKJA5xq9+0ATyXiQrwAmPcFMwnA/jzz+J/hnAHWpcJ92j8V/nRpNUqqdFC6SXE9120iIgfBANTNmEwCavT1uFitw4VLNVi00bzf1+TrInB9T+f743NDw4DZPWcvoaAGqNbVw1Pphn6h3iKXzLVcSxeYpftreLQfVHLu20ZEjsE5BoOQjWOFGry28Sgu1eihqzehVm9ErcH8oa83NTrfXS7Di7f1E6Gk1y6pVwA+2XkOu3LLEe9hbr26PsrPYRdw7K7Cr2E16N0Ng9iTYjn+h4gcBwOQE3pvyynsbGGndAulmxQeSjdkpPRFqI9zrryb0LAeUE6pFhKdOfQksPury0W0swVIEATrMgaWuiQicgSiB6ClS5fi7bffRlFREeLj4/Hee+8hISGhyXMNBgMyMzPxySefID8/H3FxcXjzzTdx2223tfuezqaqzoCfjpUAAN75UzyiAtRwl8ugksvgrpA1fC6Fyk3mVON9muPvoUC/UC8cL6rCKY25x3Y4B0B3OUsLUGmVDrp6I5RubevKyi3ToqxaD4WbFPGRPp1ZRCIiu4g6Bmjt2rXIyMjAwoULsX//fsTHxyM1NRUlJSVNnj9v3jz861//wnvvvYejR4/iySefxOTJk/H777+3+57O5ocjxdDXm9A72BP3XB+BEdH+GBThg97BnojwdYe/hwJqhVu3CD8WN1zRdSKXSRDfw1e8wrgoP7UcKrn510WRHd1glu6v6yJ92xyaiIi6gqgBaPHixZgxYwbS0tIwYMAALF++HGq1GitXrmzy/M8++wwvv/wyJkyYgNjYWMyaNQsTJkzA3//+93bf09l8fSAfAHBXfLjLrINz5Z5lA8O94a7gH9KuJpFIrHuC5dvRDbanofsrkeN/iMjBiBaA9Ho99u3bh+Tk5MuFkUqRnJyMnTt3NnmNTqeDSmU7lsXd3R07duxo9z2dSWmVzrqeyp1Dw0UuTddJjPGHJesN5zRq0Vi6wQrbuBaQefyPuQXIsqYTEZGjEG0MUFlZGYxGI0JCQmyOh4SE4Pjx401ek5qaisWLF+Pmm29Gr169kJ2djS+//BJGo7Hd9wTMwUqn01kfazQaAOYxRwaDoV2vrzN8c+ACTAIQ38MH4d4KhypbZ/KQSzA43BuH8jVI6OntMq/b0YR6m7fDOF+utfnZaK4+zl+qQWFlHdykEgwO82S9dZHW6oW6Huuk69jzHos+CNoe//d//4cZM2agX79+kEgk6NWrF9LS0q65eyszMxOLFi1qdHzr1q1Qqx1n09DP/pABkKCXWzk2bdokdnG61F3BwDAPCWpy92PTGbFL45qqSyQAZNj9x0nE1Fz+D0VWVlaT5+9uOL+H2oStP/3QNYUkq+bqhcTDOul8NTU1bT5XtAAUGBgImUyG4uJim+PFxcUIDQ1t8pqgoCBs2LABdXV1uHjxIsLDw/HSSy8hNja23fcEgLlz5yIjI8P6WKPRIDIyEmPGjEFAgGOMXcgrr8HZnTsglQDP33crgho2p3QVBoMBWVlZSElJgVzOzTTFULM/H5svHIGbdxAmTBjWap38/NVhAAVIvS4WE8b16foCuyj+rDge1knXsfTgtIVoAUihUGDYsGHIzs7GpEmTAAAmkwnZ2dlIT09v8VqVSoWIiAgYDAb897//xX333XdN91QqlVAqGwcKuVzuMN+s3x8xz2Ib2TsQ4f6eIpdGPI5UJ64msuH7rlCjs6mD5upk79kKAMANvQNZZyLgz4rjYZ10PnveX1G7wDIyMjB9+nQMHz4cCQkJWLJkCbRaLdLS0gAA06ZNQ0REBDIzMwEAu3fvRn5+PoYOHYr8/Hy8+uqrMJlMeOGFF9p8T2ckCAI2HCgAANwZ7zqDn8mxhPuaJyAUVtRCEIQWzy2srEVeeQ2kEg5cJyLHJGoAmjJlCkpLS7FgwQIUFRVh6NCh2Lx5s3UQc15eHqTSyxPV6urqMG/ePOTm5sLT0xMTJkzAZ599Bl9f3zbf0xkdK6xCTkk1FG5SpA5qviuPqDNZZoFp9UZoauuhbuE/WnsaZn8NDPeBl4r/4yUixyP6IOj09PRmu6e2bdtm83j06NE4evToNd3TGX190Lz2z9h+wfDmHxMSiUouQ4CHAhe1euRX1KJPkHuz53L6OxE5Ou4G7+BMJgEbG7q/7nKhtX/IMbV1V/jduZb9vxiAiMgxMQA5uN/OXUJBZR28lG64JS5Y7OKQiwtr2FS3oLL5AFRWrcPpUi0ABiAiclwMQA7OsvVF6qBQqOTcAoLEdbkFqPnVoC3jf/qFesFXreiSchER2YsByIHp60347o9CAOz+IscQ0YYusD0c/0NEToAByIHtyClFRY0BgZ5KJHEzSXIAbRkDtMs6/offs0TkuBiAHNjXDYOf7xgSBjcZq4rEZ1kLqLkAVFGjx4niKgAc/0NEjo1/VR1Ujb4ePx4xb+nB7i9yFJYWoCJNHeqNpkbP7z17CYIAxAZ5uNx2LUTkXBiAHFTW0WLUGozo6a/G0EhfsYtDBAAI8lRCLpPAJACl1fpGz+85Y+7+SmT3FxE5OAYgB/XNFWv/SCQSkUtDZCaVShDq03w3GBdAJCJnwQDkgC5p9dh+shQAu7/I8YT7NAyErrSdCl+tq8fh/EoAHP9DRI6PAcgBbTpciHqTgAFh3ugd7CV2cYhsRDSzFtBvZ8thEoBIf3frWCEiIkfFAOSAvuHWF+TAwiy7wl/VAnR5/R+O/yEix8cA5GAKKmqx56z5D8nEeAYgcjyW1p2rA5Bl/A+7v4jIGTAAOZhvDxVAEMx/RNiNQI7IuhjiFQGoVm/EoQsVAIAb2AJERE6AAcjBfM3uL3JwEdYWoMuzwH7PuwSDUUCotwqR/gzuROT4GIAcSE5JFY4UaOAmlWDCoDCxi0PUJMuO8JW19agzmo9Zp7/H+nPZBiJyCgxADsQy+Hl03yD4eXAXbXJMXio5vFRuAIAKnfnY7jOW/b84/oeInAMDkAP58ah564vbh7D1hxybpRvskl4CXb0Jv+dVAOAMMCJyHgxADiK/ohbHi6oglQBj4oLFLg5RiywDoS/pgD/yK6GrNyHQU4FeQR4il4yIqG0YgBzEluMlAIDre/qx+4scnmVX+Es6CfaevQTA3P3F8T9E5CwYgBzE1oYANKYfW3/I8VlbgPTAHksAiub4HyJyHm5iF4DMa6j8klMGABjbnwGIHJ9lP7CLdRIUVVYAABJjOf6HiJwHA5AD2JlbBl29CeE+KsSFcO8vcnyWFqCzVYAJRvi4y/m9S0ROhV1gDmDLFd1fHENBzsAyBsgE8/friGh/SKX83iUi58EAJDJBELDlmDkAsfuLnEWItwpX5p1Erv9DRE6GAUhkJ4qrUFBZB6WbFEmxgWIXh6hN5DIpgr2U1seJsQxARORcGIBEZun+Gtk7EO4KmcilIWo7y5YYHkoZBoR5i1waIiL7MACJzNL9xenv5GwsM8GG9fSFm4y/SojIufC3loguafXYn2deQ+VWBiByMiNi/AAA4weFilwSIiL7cRq8iLafLIVJAPqFeln3ViJyFlOH9wDy/8A914WLXRQiIruxBUhEW7j6MzkxqVQCPyW4dAMROSUGIJHUG03YfrIUADCWAYiIiKhLMQCJZH9eBSprDfBVy3FdTz+xi0NERORSGIBEYun+Gt03CDKuoEtERNSlGIBEsuV4MQDO/iIiIhIDA5AILlyqwcniakgl5hYgIiIi6loMQCLY2tD9NTzKH75qhcilISIicj2iB6ClS5ciOjoaKpUKiYmJ2LNnT4vnL1myBHFxcXB3d0dkZCSee+451NXVWZ9/9dVXIZFIbD769evX2S/DLtmc/k5ERCQqURdCXLt2LTIyMrB8+XIkJiZiyZIlSE1NxYkTJxAc3DgcrF69Gi+99BJWrlyJG2+8ESdPnsQjjzwCiUSCxYsXW88bOHAgfvrpJ+tjNzfHWe+xRl+PX09fBMDxP0RERGIRtQVo8eLFmDFjBtLS0jBgwAAsX74carUaK1eubPL8X3/9FSNHjsQDDzyA6OhojBs3DlOnTm3UauTm5obQ0FDrR2Cg4+yy/mvORejrTYjwdUffEE+xi0NEROSSRGsa0ev12LdvH+bOnWs9JpVKkZycjJ07dzZ5zY033ojPP/8ce/bsQUJCAnJzc7Fp0yY8/PDDNuedOnUK4eHhUKlUSEpKQmZmJnr27NlsWXQ6HXQ6nfWxRqMBABgMBhgMhmt5mY38dKwIAHBL30DU19d36L27M0s9dHR9UPuxThwT68XxsE66jj3vsWgBqKysDEajESEhITbHQ0JCcPz48SaveeCBB1BWVoZRo0ZBEATU19fjySefxMsvv2w9JzExER9//DHi4uJQWFiIRYsW4aabbsLhw4fh5eXV5H0zMzOxaNGiRse3bt0KtVp9Da/SliAAmw/KAEjgqTmLTZvOdNi9XUVWVpbYRaCrsE4cE+vF8bBOOl9NTU2bz3WcwTFtsG3bNrzxxhv45z//icTEROTk5GDOnDl4/fXXMX/+fADA+PHjrecPGTIEiYmJiIqKwn/+8x889thjTd537ty5yMjIsD7WaDSIjIzEmDFjEBAQ0GHlP1ZYhYpdO6GSS5F+31io5LIOu3d3ZzAYkJWVhZSUFMjlcrGLQ2CdOCrWi+NhnXQdSw9OW4gWgAIDAyGTyVBcXGxzvLi4GKGhoU1eM3/+fDz88MN4/PHHAQCDBw+GVqvFzJkz8corr0AqbTykydfXF3379kVOTk6zZVEqlVAqlY2Oy+XyDv1m/d/pcgDAqN6B8FKrOuy+rqSj64SuHevEMbFeHA/rpPPZ8/6KNghaoVBg2LBhyM7Oth4zmUzIzs5GUlJSk9fU1NQ0CjkymbkVRRCEJq+prq7G6dOnERYW1kElb7/sY+awx+nvRERE4hK1CywjIwPTp0/H8OHDkZCQgCVLlkCr1SItLQ0AMG3aNERERCAzMxMAMHHiRCxevBjXXXedtQts/vz5mDhxojUIPf/885g4cSKioqJQUFCAhQsXQiaTYerUqaK9TgAo1+rx+/kKAMCYOAYgIiIiMYkagKZMmYLS0lIsWLAARUVFGDp0KDZv3mwdGJ2Xl2fT4jNv3jxIJBLMmzcP+fn5CAoKwsSJE/HXv/7Ves6FCxcwdepUXLx4EUFBQRg1ahR27dqFoCBxt5zYdqIEggD0D/NGuK+7qGUhIiJydaIPgk5PT0d6enqTz23bts3msZubGxYuXIiFCxc2e781a9Z0ZPE6jGX391v7ce8vIiIisYm+FYYrMBhN+PlkKQDg1n4hrZxNREREnY0BqAvsO3cJmrp6+HsoMDTSV+ziEBERuTwGoC5g2f19dN8gyKQSkUtDREREDEBdYFeuefPTW+I4/oeIiMgRMAB1MkEQkFuqBWCeAUZERETiYwDqZKXVOlTp6iGRAFEBHbevGBEREbUfA1AnO9PQ+tPDzx1KN+79RURE5AgYgDpZbpk5AMUGeopcEiIiIrJgAOpkZxoCUEygh8glISIiIgsGoE6WW1oNAOgVxABERETkKBiAOlmutQWIXWBERESOggGoE9UbTci7WAMAiGELEBERkcNgAOpE5y/Vot4kQCWXIsxbJXZxiIiIqAEDUCc6U2Ye/xMd4AEpt8AgIiJyGAxAnciyAnSvII7/ISIiciQMQJ0ol1PgiYiIHBIDUCeyTIGP5QBoIiIih8IA1Im4CCIREZFjYgDqJFpdPYo1OgDcBoOIiMjRMAB1EkvrT4CHAj5qucilISIioisxAHUSDoAmIiJyXAxAnYQDoImIiBwXA1AnOcM9wIiIiBwWA1AnsSyCyBYgIiIix8MA1AkEQbC2AMVyDBAREZHDYQDqBKXVOlTr6iGVAD0D1GIXh4iIiK7CANQJLN1fPfzUULrJRC4NERERXY0BqBNwBWgiIiLHxgDUCTgFnoiIyLExAHUCDoAmIiJybHYHoOjoaLz22mvIy8vrjPJ0C5enwHMNICIiIkdkdwB69tln8eWXXyI2NhYpKSlYs2YNdDpdZ5TNKRmMJuSV1wDgGCAiIiJH1a4AdODAAezZswf9+/fH008/jbCwMKSnp2P//v2dUUancuFSLepNAlRyKUK9VWIXh4iIiJrQ7jFA119/Pd59910UFBRg4cKF+Pe//40RI0Zg6NChWLlyJQRB6MhyOg3LAOiYQE9IpRKRS0NERERNcWvvhQaDAV999RU++ugjZGVl4YYbbsBjjz2GCxcu4OWXX8ZPP/2E1atXd2RZnQIHQBMRETk+uwPQ/v378dFHH+GLL76AVCrFtGnT8I9//AP9+vWznjN58mSMGDGiQwvqLE5zDzAiIiKHZ3cX2IgRI3Dq1CksW7YM+fn5eOedd2zCDwDExMTg/vvvb9P9li5diujoaKhUKiQmJmLPnj0tnr9kyRLExcXB3d0dkZGReO6551BXV3dN9+xIZ8osXWAMQERERI7K7hag3NxcREVFtXiOh4cHPvroo1bvtXbtWmRkZGD58uVITEzEkiVLkJqaihMnTiA4OLjR+atXr8ZLL72ElStX4sYbb8TJkyfxyCOPQCKRYPHixe26Z0fjFHgiIiLHZ3cLUElJCXbv3t3o+O7du/Hbb7/Zda/FixdjxowZSEtLw4ABA7B8+XKo1WqsXLmyyfN//fVXjBw5Eg888ACio6Mxbtw4TJ061aaFx957dqRqXT1KqsxLAsQEsAWIiIjIUdndAjR79my88MILSExMtDmen5+PN998s8lw1BS9Xo99+/Zh7ty51mNSqRTJycnYuXNnk9fceOON+Pzzz7Fnzx4kJCQgNzcXmzZtwsMPP9zuewKATqezWctIo9EAMA/0NhgMbXo9AJBTZL7O30MOtRx2XUsts7yXfE8dB+vEMbFeHA/rpOvY8x7bHYCOHj2K66+/vtHx6667DkePHm3zfcrKymA0GhESEmJzPCQkBMePH2/ymgceeABlZWUYNWoUBEFAfX09nnzySbz88svtvicAZGZmYtGiRY2Ob926FWq1us2vaV+ZBIAMvlI9Nm3a1ObrqO2ysrLELgJdhXXimFgvjod10vlqamrafK7dAUipVKK4uBixsbE2xwsLC+Hm1u5Z9W2ybds2vPHGG/jnP/+JxMRE5OTkYM6cOXj99dcxf/78dt937ty5yMjIsD7WaDSIjIzEmDFjEBAQ0Ob7nN5yGjh1Gtf36YEJEwa2uzzUmMFgQFZWFlJSUiCXy8UuDoF14qhYL46HddJ1LD04bWF3Yhk3bhzmzp2Lr7/+Gj4+PgCAiooKvPzyy0hJSWnzfQIDAyGTyVBcXGxzvLi4GKGhoU1eM3/+fDz88MN4/PHHAQCDBw+GVqvFzJkz8corr7TrnoA51CmVykbH5XK5Xd+sZ8trAQC9Q7z4Td5J7K0T6nysE8fEenE8rJPOZ8/7a/cg6HfeeQfnz59HVFQUxowZgzFjxiAmJgZFRUX4+9//3ub7KBQKDBs2DNnZ2dZjJpMJ2dnZSEpKavKampoaSKW2RZbJZAAAQRDadc+OZFkEkVPgiYiIHJvdLUARERE4dOgQVq1ahYMHD8Ld3R1paWmYOnWq3ck2IyMD06dPx/Dhw5GQkIAlS5ZAq9UiLS0NADBt2jREREQgMzMTADBx4kQsXrwY1113nbULbP78+Zg4caI1CLV2z84iCIJ1G4xeXASRiIjIobVr0I6Hhwdmzpx5zV98ypQpKC0txYIFC1BUVIShQ4di8+bN1kHMeXl5Ni0+8+bNg0Qiwbx585Cfn4+goCBMnDgRf/3rX9t8z85SWqWDVm+EVAJE+rd94DQRERF1vXaPWj569Cjy8vKg1+ttjt9555123Sc9PR3p6elNPrdt2zabx25ubli4cCEWLlzY7nt2ltyG7q8efmoo3WRd+rWJiIjIPu1aCXry5Mn4448/IJFIrLu+SyTmnc+NRmPHltBJ5HIPMCIiIqdh9yDoOXPmICYmBiUlJVCr1Thy5Ah+/vlnDB8+vFGLjSvhHmBERETOw+4WoJ07d2LLli0IDAyEVCqFVCrFqFGjkJmZiWeeeQa///57Z5TT4XEPMCIiIudhdwuQ0WiEl5cXAPNaPgUFBQCAqKgonDhxomNL50QsU+Bj2QJERETk8OxuARo0aBAOHjyImJgYJCYm4q233oJCocAHH3zQaHVoV2EwmpBXbl5+m2OAiIiIHJ/dAWjevHnQas2tHa+99hruuOMO3HTTTQgICMDatWs7vIDO4Hx5DepNAtzlMoR4qcQuDhEREbXC7gCUmppq/bx37944fvw4ysvL4efnZ50J5mos3V/RgR6QSl3zPSAiInImdo0BMhgMcHNzw+HDh22O+/v7u2z4ATgFnoiIyNnYFYDkcjl69uzpsmv9NCeXA6CJiIicit2zwF555RW8/PLLKC8v74zyOCXLHmBsASIiInIOdo8Bev/995GTk4Pw8HBERUXBw8P2j/7+/fs7rHDO4vIu8FwDiIiIyBnYHYAmTZrUCcVwXlV1BpRU6QBwFWgiIiJnYXcAam0jUldztsy8/k+gpwI+7nKRS0NERERtYfcYILKVyz3AiIiInI7dLUBSqbTFKe+uNkPMOgWe43+IiIicht0B6KuvvrJ5bDAY8Pvvv+OTTz7BokWLOqxgzsI6AJozwIiIiJyG3QHorrvuanTs3nvvxcCBA7F27Vo89thjHVIwZ2HpAuMaQERERM6jw8YA3XDDDcjOzu6o2zkFQRBwhqtAExEROZ0OCUC1tbV49913ERER0RG3cxolVTpo9UZIJUBPfwYgIiIiZ2F3F9jVm54KgoCqqiqo1Wp8/vnnHVo4R2cZAB3pr4bCjRPqiIiInIXdAegf//iHTQCSSqUICgpCYmIi/Pz8OrRwju7yCtBs/SEiInImdgegRx55pBOK4Zyse4BxCjwREZFTsbvf5qOPPsK6desaHV+3bh0++eSTDimUs+AUeCIiIudkdwDKzMxEYGBgo+PBwcF44403OqRQzsISgDgFnoiIyLnYHYDy8vIQExPT6HhUVBTy8vI6pFDOorTavAlqqI9K5JIQERGRPewOQMHBwTh06FCj4wcPHkRAQECHFMoZGE0CqurqAQDeKm6CSkRE5EzsDkBTp07FM888g61bt8JoNMJoNGLLli2YM2cO7r///s4oo0Oqbgg/ALgLPBERkZOxexbY66+/jrNnz2Ls2LFwczNfbjKZMG3aNJcaA1RZawAAuMtlXAOIiIjIydgdgBQKBdauXYu//OUvOHDgANzd3TF48GBERUV1RvkclqbOHIC83e1+C4mIiEhk7f7r3adPH/Tp06cjy+JULC1A7P4iIiJyPnb33dxzzz148803Gx1/66238Kc//alDCuUMLAGIA6CJiIicj90B6Oeff8aECRMaHR8/fjx+/vnnDimUM9CwBYiIiMhp2R2AqquroVAoGh2Xy+XQaDQdUihnwC4wIiIi52V3ABo8eDDWrl3b6PiaNWswYMCADimUM7B2gTEAEREROR27B0HPnz8fd999N06fPo1bb70VAJCdnY3Vq1dj/fr1HV5AR3V5FhgDEBERkbOxOwBNnDgRGzZswBtvvIH169fD3d0d8fHx2LJlC/z9/TujjA6pstayCjSnwRMRETmbdq3gd/vtt+OXX36BVqtFbm4u7rvvPjz//POIj49vVyGWLl2K6OhoqFQqJCYmYs+ePc2ee8stt0AikTT6uP32263nPPLII42ev+2229pVtuZwEDQREZHzavcSxj///DOmT5+O8PBw/P3vf8ett96KXbt22X2ftWvXIiMjAwsXLsT+/fsRHx+P1NRUlJSUNHn+l19+icLCQuvH4cOHIZPJGk3Bv+2222zO++KLL9r1OpvDQdBERETOy67+m6KiInz88cdYsWIFNBoN7rvvPuh0OmzYsKHdA6AXL16MGTNmIC0tDQCwfPlyfPfdd1i5ciVeeumlRudf3c22Zs0aqNXqRgFIqVQiNDS0XWVqCw0HQRMRETmtNrcATZw4EXFxcTh06BCWLFmCgoICvPfee9f0xfV6Pfbt24fk5OTLBZJKkZycjJ07d7bpHitWrMD9998PDw8Pm+Pbtm1DcHAw4uLiMGvWLFy8ePGayno1yyBotgARERE5nza3AH3//fd45plnMGvWrA7bAqOsrAxGoxEhISE2x0NCQnD8+PFWr9+zZw8OHz6MFStW2By/7bbbcPfddyMmJganT5/Gyy+/jPHjx2Pnzp2QyWSN7qPT6aDT6ayPLesZGQwGGAyGRucLgmDtAlO7oclzqGNZ3mO+146DdeKYWC+Oh3XSdex5j9scgHbs2IEVK1Zg2LBh6N+/Px5++GHcf//97SpgR1mxYgUGDx6MhIQEm+NXlmvw4MEYMmQIevXqhW3btmHs2LGN7pOZmYlFixY1Or5161ao1epGx/VGwGA0v3W7/rcVqsaZijpJVlaW2EWgq7BOHBPrxfGwTjpfTU1Nm89tcwC64YYbcMMNN2DJkiVYu3YtVq5ciYyMDJhMJmRlZSEyMhJeXl52FTQwMBAymQzFxcU2x4uLi1sdv6PVarFmzRq89tprrX6d2NhYBAYGIicnp8kANHfuXGRkZFgfazQaREZGYsyYMQgICGh0fpGmDtjzM2RSCSbfMR4SiaTVMtC1MRgMyMrKQkpKCuRydjs6AtaJY2K9OB7WSdexZ0cKuxex8fDwwKOPPopHH30UJ06cwIoVK/C3v/0NL730ElJSUvDNN9+0+V4KhQLDhg1DdnY2Jk2aBAAwmUzIzs5Genp6i9euW7cOOp0ODz30UKtf58KFC7h48SLCwsKafF6pVEKpVDY6LpfLm/xmrTHUATCvAdTUtiDUeZqrExIP68QxsV4cD+uk89nz/rZ7GjwAxMXF4a233sKFCxfaPc08IyMDH374IT755BMcO3YMs2bNglartc4KmzZtGubOndvouhUrVmDSpEmNWmiqq6vx5z//Gbt27cLZs2eRnZ2Nu+66C71790Zqamq7yng1DoAmIiJybh2yjLFMJsOkSZOsrTj2mDJlCkpLS7FgwQIUFRVh6NCh2Lx5s3VgdF5eHqRS25x24sQJ7NixAz/++GOTZTl06BA++eQTVFRUIDw8HOPGjcPrr7/eZCtPe1TWMAARERE5M4fYxyE9Pb3ZLq9t27Y1OhYXFwdBEJo8393dHT/88ENHFq8R7gNGRETk3K6pC8xVcSd4IiIi58YA1A7WAKRiACIiInJGDEDtoGnYCZ5jgIiIiJwTA1A7cCNUIiIi58YA1A6XB0E7xBhyIiIishMDUDuwBYiIiMi5MQC1g4aDoImIiJwaA1A7aNgCRERE5NQYgNqBXWBERETOjQHITvVGE7R6IwAuhEhEROSsGIDspKmrt37ureIsMCIiImfEAGQnS/eXh0IGNxnfPiIiImfEv+B24gBoIiIi58cAZCduhEpEROT8GIDsdHkVaAYgIiIiZ8UAZCdOgSciInJ+DEB2quQq0ERERE6PAchOmlrzNHi2ABERETkvBiA7sQuMiIjI+TEA2enyIGgugkhEROSsGIDsxHWAiIiInB8DkJ04CJqIiMj5MQDZydoCpGYAIiIiclYMQHbiIGgiIiLnxwBkB0EQrLvBswuMiIjIeTEA2UGrN8JoEgCwBYiIiMiZMQDZwdL9JZdJoJLzrSMiInJW/CtuhyunwEskEpFLQ0RERO3FAGQH6xR4dn8RERE5NQYgO3ANICIiou6BAcgOXAWaiIioe2AAsgPXACIiIuoeGIDsYF0DiBuhEhEROTUGIDuwC4yIiKh7YACyAwdBExERdQ8MQHZgCxAREVH3wABkBw6CJiIi6h4cIgAtXboU0dHRUKlUSExMxJ49e5o995ZbboFEImn0cfvtt1vPEQQBCxYsQFhYGNzd3ZGcnIxTp05dczk1dVwIkYiIqDsQPQCtXbsWGRkZWLhwIfbv34/4+HikpqaipKSkyfO//PJLFBYWWj8OHz4MmUyGP/3pT9Zz3nrrLbz77rtYvnw5du/eDQ8PD6SmpqKuru6aysoWICIiou5B9AC0ePFizJgxA2lpaRgwYACWL18OtVqNlStXNnm+v78/QkNDrR9ZWVlQq9XWACQIApYsWYJ58+bhrrvuwpAhQ/Dpp5+ioKAAGzZsuKaychA0ERFR9yDqgjZ6vR779u3D3LlzrcekUimSk5Oxc+fONt1jxYoVuP/+++Hh4QEAOHPmDIqKipCcnGw9x8fHB4mJidi5cyfuv//+RvfQ6XTQ6XTWxxqNBgBgMBhgMJhDj67ehDqDCQCglsN6nLqG5f3m++44WCeOifXieFgnXcee91jUAFRWVgaj0YiQkBCb4yEhITh+/Hir1+/ZsweHDx/GihUrrMeKioqs97j6npbnrpaZmYlFixY1Or5161ao1WoAgEYPAG6QQMD/tmRBys3gRZGVlSV2EegqrBPHxHpxPKyTzldTU9Pmc516SeMVK1Zg8ODBSEhIuKb7zJ07FxkZGdbHGo0GkZGRGDNmDAICAgAAuaVaYN8v8FTJccftqdf09ch+BoMBWVlZSElJgVzOLkhHwDpxTKwXx8M66TqWHpy2EDUABQYGQiaTobi42OZ4cXExQkNDW7xWq9VizZo1eO2112yOW64rLi5GWFiYzT2HDh3a5L2USiWUSmWj43K53PrNqq0XAJgHQPMbWDxX1gk5BtaJY2K9OB7WSeez5/0VdRC0QqHAsGHDkJ2dbT1mMpmQnZ2NpKSkFq9dt24ddDodHnroIZvjMTExCA0NtbmnRqPB7t27W71nSzgAmoiIqPsQvQssIyMD06dPx/Dhw5GQkIAlS5ZAq9UiLS0NADBt2jREREQgMzPT5roVK1Zg0qRJ1i4qC4lEgmeffRZ/+ctf0KdPH8TExGD+/PkIDw/HpEmT2l1OrgJNRETUfYgegKZMmYLS0lIsWLAARUVFGDp0KDZv3mwdxJyXlwep1Lah6sSJE9ixYwd+/PHHJu/5wgsvQKvVYubMmaioqMCoUaOwefNmqFSqdpeTAYiIiKj7ED0AAUB6ejrS09ObfG7btm2NjsXFxUEQhGbvJ5FI8NprrzUaH3QtNHX1AABvd4d4y4iIiOgaiL4QorPgKtBERETdBwNQG1XWcBA0ERFRd8EA1EaWjVB91AxAREREzo4BqI3YBUZERNR9MAC1kaUFiF1gREREzo8BqI2sCyGyBYiIiMjpMQC1kWUQtA+nwRMRETk9BqA2MJkEVOks6wCxBYiIiMjZMQC1QZWuHpZ1FzkGiIiIyPkxALWBZRsMpZsUKrlM5NIQERHRtWIAagNOgSciIupeGIDagBuhEhERdS8MQG1gXQOIAYiIiKhbYABqA3aBERERdS8MQG1gXQRRxTWAiIiIugMGoDbQ1JrXAGILEBERUffAANQG7AIjIiLqXhiA2oCDoImIiLoXBqA24EaoRERE3QsDUBtcHgTNAERERNQdMAC1ARdCJCIi6l4YgNqgkrPAiIiIuhUGoDa4PAia6wARERF1BwxAragzGKGvNwFgCxAREVF3wQDUCssAaKkE8FCwBYiIiKg7YABqheaKKfBSqUTk0hAREVFHYABqBVeBJiIi6n4YgFphHQDNNYCIiIi6DQagVrAFiIiIqPthAGpFZQ2nwBMREXU3DECt0NRxEUQiIqLuhgGoFdwIlYiIqPthAGqFhhuhEhERdTsMQK3gIGgiIqLuhwGoFewCIyIi6n4YgFrBQdBERETdj+gBaOnSpYiOjoZKpUJiYiL27NnT4vkVFRWYPXs2wsLCoFQq0bdvX2zatMn6/KuvvgqJRGLz0a9fv3aXT8MuMCIiom5H1MVt1q5di4yMDCxfvhyJiYlYsmQJUlNTceLECQQHBzc6X6/XIyUlBcHBwVi/fj0iIiJw7tw5+Pr62pw3cOBA/PTTT9bHbm7tf5mXB0FzHSAiIqLuQtS/6osXL8aMGTOQlpYGAFi+fDm+++47rFy5Ei+99FKj81euXIny8nL8+uuvkMvNLTLR0dGNznNzc0NoaOg1l89oElClYxcYERFRdyNaANLr9di3bx/mzp1rPSaVSpGcnIydO3c2ec0333yDpKQkzJ49G19//TWCgoLwwAMP4MUXX4RMJrOed+rUKYSHh0OlUiEpKQmZmZno2bNns2XR6XTQ6XTWxxqNBgBwqbrWeszdDTAYDO1+vXRtLO8968BxsE4cE+vF8bBOuo4977FoAaisrAxGoxEhISE2x0NCQnD8+PEmr8nNzcWWLVvw4IMPYtOmTcjJycFTTz0Fg8GAhQsXAgASExPx8ccfIy4uDoWFhVi0aBFuuukmHD58GF5eXk3eNzMzE4sWLWp0PGvbDgDeUEgFZP2w+dpeMHWIrKwssYtAV2GdOCbWi+NhnXS+mpqaNp/rVANbTCYTgoOD8cEHH0Amk2HYsGHIz8/H22+/bQ1A48ePt54/ZMgQJCYmIioqCv/5z3/w2GOPNXnfuXPnIiMjw/pYo9EgMjISA4YOB06chL+nChMmjO7cF0ctMhgMyMrKQkpKirX7k8TFOnFMrBfHwzrpOpYenLYQLQAFBgZCJpOhuLjY5nhxcXGz43fCwsIgl8tturv69++PoqIi6PV6KBSKRtf4+vqib9++yMnJabYsSqUSSqWy0fFao/lfH3cFv2kdhFwuZ104GNaJY2K9OB7WSeez5/0VbRq8QqHAsGHDkJ2dbT1mMpmQnZ2NpKSkJq8ZOXIkcnJyYDKZrMdOnjyJsLCwJsMPAFRXV+P06dMICwuzu4xVnAJPRETULYm6DlBGRgY+/PBDfPLJJzh27BhmzZoFrVZrnRU2bdo0m0HSs2bNQnl5OebMmYOTJ0/iu+++wxtvvIHZs2dbz3n++eexfft2nD17Fr/++ismT54MmUyGqVOn2l0+yyKIXAWaiIioexF1DNCUKVNQWlqKBQsWoKioCEOHDsXmzZutA6Pz8vIglV7OaJGRkfjhhx/w3HPPYciQIYiIiMCcOXPw4osvWs+5cOECpk6diosXLyIoKAijRo3Crl27EBQUZHf5LgcgpxoqRURERK0Q/S97eno60tPTm3xu27ZtjY4lJSVh165dzd5vzZo1HVU0VHEbDCIiom5J9K0wHJmmzrIKNAMQERFRd8IA1IJqtgARERF1SwxALeBO8ERERN0TA1ALrF1gDEBERETdCgNQCzgImoiIqHtiAGqBptbSAiT6ZDkiIiLqQAxALajWmffCYAsQERFR98IA1IJ6kwCAAYiIiKi7YQBqhZtUAne5rPUTiYiIyGkwALXCx10OiUQidjGIiIioAzEAtYJT4ImIiLofBqBWMAARERF1PwxAreAAaCIiou6HAagV3iquAURERNTdMAC1gi1ARERE3Q8DUCs4BoiIiKj7YQBqBVuAiIiIuh8GoFYwABEREXU/DECt8FYxABEREXU3DECtYAsQERFR98MA1AoGICIiou6HAagV3u5cB4iIiKi7YQBqBVuAiIiIuh8GoFZ4cRA0ERFRt8MA1AIPpQwyqUTsYhAREVEHYwBqAfcBIyIi6p4YgFrA7i8iIqLuiQGoBWwBIiIi6p4YgFrgxQBERETULTEAtYABiIiIqHtiAGoB9wEjIiLqnhiAWuClZAsQERFRd8QA1AJug0FERNQ9MQC1gC1ARERE3RMDUAu8uA8YERFRt8QA1AIfDoImIiLqlkQPQEuXLkV0dDRUKhUSExOxZ8+eFs+vqKjA7NmzERYWBqVSib59+2LTpk3XdM/meKpk7bqOiIiIHJuoAWjt2rXIyMjAwoULsX//fsTHxyM1NRUlJSVNnq/X65GSkoKzZ89i/fr1OHHiBD788ENERES0+54t4TR4IiKi7knUALR48WLMmDEDaWlpGDBgAJYvXw61Wo2VK1c2ef7KlStRXl6ODRs2YOTIkYiOjsbo0aMRHx/f7nu2hAshEhERdU+iBSC9Xo99+/YhOTn5cmGkUiQnJ2Pnzp1NXvPNN98gKSkJs2fPRkhICAYNGoQ33ngDRqOx3fdsiUrOLjAiIqLuSLQmjrKyMhiNRoSEhNgcDwkJwfHjx5u8Jjc3F1u2bMGDDz6ITZs2IScnB0899RQMBgMWLlzYrnsCgE6ng06nsz7WaDQAAIPBAIPB0N6XSB3IUg+sD8fBOnFMrBfHwzrpOva8x07Vx2MymRAcHIwPPvgAMpkMw4YNQ35+Pt5++20sXLiw3ffNzMzEokWLGh3funUr1Gr1tRSZOlhWVpbYRaCrsE4cE+vF8bBOOl9NTU2bzxUtAAUGBkImk6G4uNjmeHFxMUJDQ5u8JiwsDHK5HDLZ5a6p/v37o6ioCHq9vl33BIC5c+ciIyPD+lij0SAyMhJjxoxBQEBAe14edTCDwYCsrCykpKRALufgdEfAOnFMrBfHwzrpOpYenLYQLQApFAoMGzYM2dnZmDRpEgBzC092djbS09ObvGbkyJFYvXo1TCYTpFLz8KWTJ08iLCwMCoUCAOy+JwAolUoolcpGx+VyOb9ZHQzrxPGwThwT68XxsE46nz3vr6izwDIyMvDhhx/ik08+wbFjxzBr1ixotVqkpaUBAKZNm4a5c+daz581axbKy8sxZ84cnDx5Et999x3eeOMNzJ49u833JCIiIhJ1DNCUKVNQWlqKBQsWoKioCEOHDsXmzZutg5jz8vKsLT0AEBkZiR9++AHPPfcchgwZgoiICMyZMwcvvvhim+9JREREJPog6PT09Ga7p7Zt29boWFJSEnbt2tXuexIRERGJvhUGERERUVdjACIiIiKXwwBERERELocBiIiIiFwOAxARERG5HAYgIiIicjkMQERERORyRF8HyBEJggAAqKqq4rLlDsJgMKCmpgYajYZ14iBYJ46J9eJ4WCddx7IXmOXveEsYgJpw8eJFAEBMTIzIJSEiIiJ7VVVVwcfHp8VzGICa4O/vD8C8FUdrbyB1DY1Gg8jISJw/fx7e3t5iF4fAOnFUrBfHwzrpOoIgoKqqCuHh4a2eywDUBMv+Yz4+PvxmdTDe3t6sEwfDOnFMrBfHwzrpGm1tuOAgaCIiInI5DEBERETkchiAmqBUKrFw4UIolUqxi0INWCeOh3XimFgvjod14pgkQlvmihERERF1I2wBIiIiIpfDAEREREQuhwGIiIiIXA4DEBEREbkcBqAmLF26FNHR0VCpVEhMTMSePXvELpLL+PnnnzFx4kSEh4dDIpFgw4YNNs8LgoAFCxYgLCwM7u7uSE5OxqlTp8QprIvIzMzEiBEj4OXlheDgYEyaNAknTpywOaeurg6zZ89GQEAAPD09cc8996C4uFikEnd/y5Ytw5AhQ6wL6yUlJeH777+3Ps/6EN/f/vY3SCQSPPvss9ZjrBfHwgB0lbVr1yIjIwMLFy7E/v37ER8fj9TUVJSUlIhdNJeg1WoRHx+PpUuXNvn8W2+9hXfffRfLly/H7t274eHhgdTUVNTV1XVxSV3H9u3bMXv2bOzatQtZWVkwGAwYN24ctFqt9ZznnnsOGzduxLp167B9+3YUFBTg7rvvFrHU3VuPHj3wt7/9Dfv27cNvv/2GW2+9FXfddReOHDkCgPUhtr179+Jf//oXhgwZYnOc9eJgBLKRkJAgzJ492/rYaDQK4eHhQmZmpoilck0AhK+++sr62GQyCaGhocLbb79tPVZRUSEolUrhiy++EKGErqmkpEQAIGzfvl0QBHMdyOVyYd26ddZzjh07JgAQdu7cKVYxXY6fn5/w73//m/UhsqqqKqFPnz5CVlaWMHr0aGHOnDmCIPDnxBGxBegKer0e+/btQ3JysvWYVCpFcnIydu7cKWLJCADOnDmDoqIim/rx8fFBYmIi66cLVVZWAri8afC+fftgMBhs6qVfv37o2bMn66ULGI1GrFmzBlqtFklJSawPkc2ePRu33367zfsP8OfEEXEz1CuUlZXBaDQiJCTE5nhISAiOHz8uUqnIoqioCACarB/Lc9S5TCYTnn32WYwcORKDBg0CYK4XhUIBX19fm3NZL53rjz/+QFJSEurq6uDp6YmvvvoKAwYMwIEDB1gfIlmzZg3279+PvXv3NnqOPyeOhwGIiNps9uzZOHz4MHbs2CF2UVxeXFwcDhw4gMrKSqxfvx7Tp0/H9u3bxS6Wyzp//jzmzJmDrKwsqFQqsYtDbcAusCsEBgZCJpM1GpVfXFyM0NBQkUpFFpY6YP2IIz09Hd9++y22bt2KHj16WI+HhoZCr9ejoqLC5nzWS+dSKBTo3bs3hg0bhszMTMTHx+P//u//WB8i2bdvH0pKSnD99dfDzc0Nbm5u2L59O9599124ubkhJCSE9eJgGICuoFAoMGzYMGRnZ1uPmUwmZGdnIykpScSSEQDExMQgNDTUpn40Gg12797N+ulEgiAgPT0dX331FbZs2YKYmBib54cNGwa5XG5TLydOnEBeXh7rpQuZTCbodDrWh0jGjh2LP/74AwcOHLB+DB8+HA8++KD1c9aLY2EX2FUyMjIwffp0DB8+HAkJCViyZAm0Wi3S0tLELppLqK6uRk5OjvXxmTNncODAAfj7+6Nnz5549tln8Ze//AV9+vRBTEwM5s+fj/DwcEyaNEm8Qndzs2fPxurVq/H111/Dy8vLOl7Bx8cH7u7u8PHxwWOPPYaMjAz4+/vD29sbTz/9NJKSknDDDTeIXPruae7cuRg/fjx69uyJqqoqrF69Gtu2bcMPP/zA+hCJl5eXdVychYeHBwICAqzHWS8ORuxpaI7ovffeE3r27CkoFAohISFB2LVrl9hFchlbt24VADT6mD59uiAI5qnw8+fPF0JCQgSlUimMHTtWOHHihLiF7uaaqg8AwkcffWQ9p7a2VnjqqacEPz8/Qa1WC5MnTxYKCwvFK3Q39+ijjwpRUVGCQqEQgoKChLFjxwo//vij9XnWh2O4chq8ILBeHI1EEARBpOxFREREJAqOASIiIiKXwwBERERELocBiIiIiFwOAxARERG5HAYgIiIicjkMQERERORyGICIiIjI5TAAERG1gUQiwYYNG8QuBhF1EAYgInJ4jzzyCCQSSaOP2267TeyiEZGT4l5gROQUbrvtNnz00Uc2x5RKpUilISJnxxYgInIKSqUSoaGhNh9+fn4AzN1Ty5Ytw/jx4+Hu7o7Y2FisX7/e5vo//vgDt956K9zd3REQEICZM2eiurra5pyVK1di4MCBUCqVCAsLQ3p6us3zZWVlmDx5MtRqNfr06YNvvvmmc180EXUaBiAi6hbmz5+Pe+65BwcPHsSDDz6I+++/H8eOHQMAaLVapKamws/PD3v37sW6devw008/2QScZcuWYfbs2Zg5cyb++OMPfPPNN+jdu7fN11i0aBHuu+8+HDp0CBMmTMCDDz6I8vLyLn2dRNRBxN6NlYioNdOnTxdkMpng4eFh8/HXv/5VEATzjvVPPvmkzTWJiYnCrFmzBEEQhA8++EDw8/MTqqurrc9/9913glQqFYqKigRBEITw8HDhlVdeabYMAIR58+ZZH1dXVwsAhO+//77DXicRdR2OASIipzBmzBgsW7bM5pi/v7/186SkJJvnkpKScODAAQDAsWPHEB8fDw8PD+vzI0eOhMlkwokTJyCRSFBQUICxY8e2WIYhQ4ZYP/fw8IC3tzdKSkra+5KISEQMQETkFDw8PBp1SXUUd3f3Np0nl8ttHkskEphMps4oEhF1Mo4BIqJuYdeuXY0e9+/fHwDQv39/HDx4EFqt1vr8L7/8AqlUiri4OHh5eSE6OhrZ2dldWmYiEg9bgIjIKeh0OhQVFdkcc3NzQ2BgIABg3bp1GD58OEaNGoVVq1Zhz549WLFiBQDgwQcfxMKFCzF9+nS8+uqrKC0txdNPP42HH34YISEhAIBXX30VTz75JIKDgzF+/HhUVVXhl19+wdNPP921L5SIugQDEBE5hc2bNyMsLMzmWFxcHI4fPw7APENrzZo1eOqppxAWFoYvvvgCAwYMAACo1Wr88MMPmDNnDkaMGAG1Wo177rkHixcvtt5r+vTpqKurwz/+8Q88//zzCAwMxL333tt1L5CIupREEARB7EIQEV0LiUSCr776CpMmTRK7KETkJDgGiIiIiFwOAxARERG5HI4BIiKnx558IrIXW4CIiIjI5TAAERERkcthACIiIiKXwwBERERELocBiIiIiFwOAxARERG5HAYgIiIicjkMQERERORyGICIiIjI5fx/91ctB1XSikUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 87.71632168306752\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib\n",
    "# matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load a single file as a numpy array\n",
    "def load_file(filepath):\n",
    "    dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
    "    print(\"dataframe.shape:{}\".format(dataframe.shape))\n",
    "    return dataframe.values\n",
    "\n",
    "# load a list of files into a 3D array of [samples, timesteps, features]\n",
    "def load_group(filenames, prefix=''):\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = load_file(prefix + name)\n",
    "        loaded.append(data)\n",
    "    # stack group so that features are the 3rd dimension\n",
    "    print('load_group before dstack:{}'.format(np.shape(loaded)))\n",
    "    loaded = np.dstack(loaded)\n",
    "    print('load_group after dstack:{}'.format(np.shape(loaded)))\n",
    "    return loaded\n",
    "\n",
    "# load a dataset group, such as train or test\n",
    "def load_dataset_group(group, prefix=''):\n",
    "    filepath = prefix + group + '/Inertial Signals/'\n",
    "    # load all 9 files as a single array\n",
    "    filenames = list()\n",
    "    # total acceleration\n",
    "    filenames += ['total_acc_x_' + group + '.txt', 'total_acc_y_' + group + '.txt', 'total_acc_z_' + group + '.txt']\n",
    "    # body acceleration\n",
    "    filenames += ['body_acc_x_' + group + '.txt', 'body_acc_y_' + group + '.txt', 'body_acc_z_' + group + '.txt']\n",
    "    # body gyroscope\n",
    "    filenames += ['body_gyro_x_' + group + '.txt', 'body_gyro_y_' + group + '.txt', 'body_gyro_z_' + group + '.txt']\n",
    "    # load input data\n",
    "    X = load_group(filenames, filepath)\n",
    "    # load class output\n",
    "    y = load_file(prefix + group + '/y_' + group + '.txt')\n",
    "    print(\"line 42, y:{}\".format(y.shape))\n",
    "    return X, y\n",
    "\n",
    "def to_categorical(y, num_classes=None, dtype='float32'):\n",
    "    \"\"\"Converts a class vector (integers) to binary class matrix.\n",
    "    E.g. for use with categorical_crossentropy.\n",
    "    # Arguments\n",
    "        y: class vector to be converted into a matrix\n",
    "            (integers from 0 to num_classes).\n",
    "        num_classes: total number of classes.\n",
    "        dtype: The data type expected by the input, as a string\n",
    "            (`float32`, `float64`, `int32`...)\n",
    "    # Returns\n",
    "        A binary matrix representation of the input. The classes axis\n",
    "        is placed last.\n",
    "    # Example\n",
    "    ```python\n",
    "    # Consider an array of 5 labels out of a set of 3 classes {0, 1, 2}:\n",
    "    > labels\n",
    "    array([0, 2, 1, 2, 0])\n",
    "    # `to_categorical` converts this into a matrix with as many\n",
    "    # columns as there are classes. The number of rows\n",
    "    # stays the same.\n",
    "    > to_categorical(labels)\n",
    "    array([[ 1.,  0.,  0.],\n",
    "           [ 0.,  0.,  1.],\n",
    "           [ 0.,  1.,  0.],\n",
    "           [ 0.,  0.,  1.],\n",
    "           [ 1.,  0.,  0.]], dtype=float32)\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    y = np.array(y, dtype='int')\n",
    "    input_shape = y.shape\n",
    "    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n",
    "        input_shape = tuple(input_shape[:-1])\n",
    "    y = y.ravel()\n",
    "    if not num_classes:\n",
    "        num_classes = np.max(y) + 1\n",
    "    n = y.shape[0]\n",
    "    categorical = np.zeros((n, num_classes), dtype=dtype)\n",
    "    categorical[np.arange(n), y] = 1\n",
    "    output_shape = input_shape + (num_classes,)\n",
    "    categorical = np.reshape(categorical, output_shape)\n",
    "    return categorical\n",
    "\n",
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(prefix=''):\n",
    "    # load all train\n",
    "    trainX, trainy = load_dataset_group('train', prefix)\n",
    "    print('line 91,after load_dataset_group train x,y shape:{},{}'.format(trainX.shape, trainy.shape))\n",
    "    # load all test\n",
    "    testX, testy = load_dataset_group('test', prefix)\n",
    "    print('line 94,after load_dataset_group test x,y shape:{},{}'.format(testX.shape, testy.shape))\n",
    "    # zero-offset class values\n",
    "    trainy = trainy - 1\n",
    "    testy = testy - 1\n",
    "    # one hot encode y\n",
    "    trainy = to_categorical(trainy)\n",
    "    testy = to_categorical(testy)\n",
    "    print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "    print(type(trainy), type(testy))\n",
    "    return trainX, trainy, testX, testy\n",
    "\n",
    "# load data set and split into training and testing inputs (X) and outputs (y)\n",
    "trainX, trainy, testX, testy = load_dataset('D:/vscode_workspace/PracticeLab/IMU/code/dataset/UCI HAR Dataset/')\n",
    "\n",
    "print(\"after load_dataset, shape of all: {} {} {} {}\".format(trainX.shape, trainy.shape, testX.shape, testy.shape))\n",
    "\n",
    "n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "\n",
    "# define the model using pytorch\n",
    "class ConvNet1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(n_features, 64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.MaxPool1d(10))\n",
    "        self.layer2 = nn.Flatten()\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(768,100),\n",
    "            nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Linear(100,6),\n",
    "            nn.Softmax())\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        return out\n",
    "\n",
    "model = ConvNet1D()\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(trainX)\n",
    "print(\"shape of all: {} {} {} {}\".format(trainX.shape, trainy.shape, testX.shape, testy.shape))\n",
    "\n",
    "# transformation of data into torch tensors\n",
    "trainXT = torch.from_numpy(trainX)\n",
    "trainXT = trainXT.transpose(1,2).float() #input is (N, Cin, Lin) = Ntimesteps, Nfeatures, 128\n",
    "trainyT = torch.from_numpy(trainy).float()\n",
    "testXT = torch.from_numpy(testX)\n",
    "testXT = testXT.transpose(1,2).float()\n",
    "testyT = torch.from_numpy(testy).float()\n",
    "print(\"trainXT.shape: {}, trainyT.shape: {}, testXT.shape:{}, testyT.shape:{}\".format(trainXT.shape, trainyT.shape, testXT.shape, testyT.shape))\n",
    "\n",
    "num_epochs = 50\n",
    "batch_size = 32\n",
    "\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "acc_list_epoch = []\n",
    "for epoch in range(num_epochs):\n",
    "    correct_sum = 0\n",
    "    for i in range(int(np.floor(total_step/batch_size))): # split data into batches\n",
    "        trainXT_seg = trainXT[i*batch_size:(i+1)*batch_size]\n",
    "        trainyT_seg = trainyT[i*batch_size:(i+1)*batch_size]\n",
    "        # Run the forward pass\n",
    "        outputs = model(trainXT_seg)\n",
    "        loss = criterion(outputs, torch.max(trainyT_seg, 1)[1])\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        # Backprop and perform Adam optimisation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Track the accuracy\n",
    "        total = trainyT_seg.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        _, actual = torch.max(trainyT_seg, 1)\n",
    "        correct = (predicted == actual).sum().item()\n",
    "        correct_sum = correct_sum + (correct/total)\n",
    "        acc_list.append(correct / total)\n",
    "    print(\"Epoch: {}\".format(epoch))\n",
    "    print(\"accuracy: {}\".format(correct_sum/int(np.floor(total_step/batch_size))))\n",
    "    acc_list_epoch.append(correct_sum/int(np.floor(total_step/batch_size)))\n",
    "\n",
    "#plot the training accuracy\n",
    "plt.title('Training Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.grid(True)\n",
    "plt.autoscale(axis='x', tight=True)\n",
    "plt.plot(acc_list_epoch)\n",
    "plt.show()\n",
    "\n",
    "# Test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(testXT)\n",
    "    _, predictedt = torch.max(test_outputs, 1)\n",
    "    _, actual = torch.max(testyT, 1)\n",
    "    total_t = testyT.size(0)\n",
    "    correct_t = (predictedt == actual).sum().item()\n",
    "    print('Test accuracy: {}'.format((correct_t/total_t)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 35, 100])\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)\n",
    "\n",
    "# in_channels: 输入的通道数\n",
    "# out_channels:输出的通道数\n",
    "# kernel_size:卷积核的大小\n",
    "# stride:每次移动卷积核的间距\n",
    "# padding:每个边padding的元素数\n",
    "# dilation:空洞卷积的参数\n",
    "# groups:分组卷积的组数\n",
    "\n",
    "conv1 = nn.Conv1d(in_channels=256, out_channels=100, kernel_size=2)\n",
    "\n",
    "# 输出的特征\n",
    "input = torch.randn(32, 35, 256)\n",
    "# 加padding是为了让卷积之后的时间维度不变\n",
    "padding = nn.ConstantPad2d((1, 0, 0, 0,), 0)\n",
    "# 由于一维卷积是对最后一维操作的，所以得转置后面两维\n",
    "input = input.transpose(2, 1)\n",
    "# 先转置，后padding，这样padding就加在了时间维度了\n",
    "input = padding(input)\n",
    "# 卷积之后还得恢复到原来的维度\n",
    "output = conv1(input).transpose(2, 1)\n",
    "print(output.shape)   # torch.Size([32, 35, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2947, 128)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv(r'D:\\vscode_workspace\\PracticeLab\\IMU\\code\\dataset\\UCI HAR Dataset\\test\\Inertial Signals\\total_acc_z_test.txt', header=None, delim_whitespace=True)\n",
    "# df1 = pd.read_csv(r'D:\\vscode_workspace\\PracticeLab\\IMU_concat2.txt', header=0, sep='\\t')\n",
    "\n",
    "print(df_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A-x</th>\n",
       "      <th>A-y</th>\n",
       "      <th>A-z</th>\n",
       "      <th>W-x</th>\n",
       "      <th>W-y</th>\n",
       "      <th>W-z</th>\n",
       "      <th>user</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.3320</td>\n",
       "      <td>1.1172</td>\n",
       "      <td>0.1133</td>\n",
       "      <td>-2.8099</td>\n",
       "      <td>-1.6406</td>\n",
       "      <td>0.5236</td>\n",
       "      <td>1</td>\n",
       "      <td>up stairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.1016</td>\n",
       "      <td>0.9063</td>\n",
       "      <td>-0.1094</td>\n",
       "      <td>-2.7925</td>\n",
       "      <td>-2.1118</td>\n",
       "      <td>0.6632</td>\n",
       "      <td>1</td>\n",
       "      <td>up stairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.8359</td>\n",
       "      <td>-0.1133</td>\n",
       "      <td>-2.5132</td>\n",
       "      <td>-2.5656</td>\n",
       "      <td>0.6981</td>\n",
       "      <td>1</td>\n",
       "      <td>up stairs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A-x     A-y     A-z     W-x     W-y     W-z  user       type\n",
       "0 -0.3320  1.1172  0.1133 -2.8099 -1.6406  0.5236     1  up stairs\n",
       "1 -0.1016  0.9063 -0.1094 -2.7925 -2.1118  0.6632     1  up stairs\n",
       "2  0.1328  0.8359 -0.1133 -2.5132 -2.5656  0.6981     1  up stairs"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.332, 1.1172, 0.1133, -2.8099, -1.6406, 0.5236, 1, 'up stairs'],\n",
       "       [-0.1016, 0.9063, -0.1094, -2.7925, -2.1118, 0.6632, 1,\n",
       "        'up stairs'],\n",
       "       [0.1328, 0.8359, -0.1133, -2.5132, -2.5656, 0.6981, 1,\n",
       "        'up stairs']], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.values[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list = list()\n",
    "\n",
    "t_list.append(df1.type[0:3])\n",
    "t_list.append(df1.type[3:6])\n",
    "\n",
    "print(np.shape(t_list))\n",
    "len(t_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list = list()\n",
    "\n",
    "t_list.append(df1['type'].values[0:3])\n",
    "t_list.append(df1['type'].values[3:6])\n",
    "print(np.shape(t_list))\n",
    "\n",
    "len(t_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot select an axis to squeeze out which has size not equal to one",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_list\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot select an axis to squeeze out which has size not equal to one"
     ]
    }
   ],
   "source": [
    "np.array(t_list).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train ,df_test = train_test_split(df1, test_size=0.3, random_state=42)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "# y_train = label_encoder.fit_transform(df_train.type)\n",
    "# y_test = label_encoder.fit_transform(df_test.type)\n",
    "\n",
    "# y_train, y_test, df_train.shape, y_train.shape, df_test.shape, y_test.shape\n",
    "\n",
    "X_train_list = list()\n",
    "X_test_list = list()\n",
    "y_train_list = list()\n",
    "y_test_list = list()\n",
    "\n",
    "train_labels = []\n",
    "test_labels = []\n",
    "\n",
    "window_size = 96\n",
    "step_size = 48 # 50% overlaped\n",
    "\n",
    "# creating overlaping windows of size window-size 100\n",
    "for i in range(0, df_train.shape[0] - window_size, step_size):\n",
    "    xlist = pd.DataFrame(df_train.values[i: i + 96])\n",
    "    # W_xs = df_train['W-x'].values[i: i + 96]\n",
    "    # train_label = stats.mode(df_train['type'][i: i + 96])[0][0]\n",
    "    train_label = pd.DataFrame(df_train['type'][i: i + 96])\n",
    "\n",
    "    X_train_list.append(xlist)\n",
    "    train_labels.append(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, df_test.shape[0] - window_size, step_size):\n",
    "    xlist = df_test.values[i: i + 96].values\n",
    "    # W_xs = df_train['W-x'].values[i: i + 96]\n",
    "    test_label = stats.mode(df_test['type'][i: i + 96])[0][0]\n",
    "\n",
    "    X_test_list.append(xlist)\n",
    "    test_labels.append(test_label)\n",
    "\n",
    "np.shape(X_train_list), np.shape(y_train_list), np.shape(X_test_list), np.shape(y_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1352580,), (1352580, 6))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns\n",
    "\n",
    "df_y = df1['type']\n",
    "df2 = df1.drop(labels='type', axis=1)\n",
    "df2 = df2.drop(labels='user', axis=1)\n",
    "df_y.shape, df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A-x', 'A-y', 'A-z', 'W-x', 'W-y', 'W-z'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "loaded.shape:(6, 1352580)\n",
      "after dstack:(1, 1352580, 6)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "loaded = list()\n",
    "for name in df2.columns:\n",
    "    # print(type(pd.DataFrame(df2[name]).values))\n",
    "    print(type(df2[name].values))\n",
    "    # data = pd.DataFrame(df2[name]).values\n",
    "    data = df2[name].values\n",
    "    loaded.append(data)\n",
    "print('loaded.shape:{}'.format(np.shape(loaded)))\n",
    "loaded = np.dstack(loaded)\n",
    "print('after dstack:{}'.format(np.shape(loaded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv1d(in_channels=256,out_channels=100,kernel_size=2)\n",
    "# input = torch.randn(32, 100, 6)\n",
    "input = torch.randn(32,35,256)  # 32 256 35\n",
    "# batch_size x text_len x embedding_size -> batch_size x embedding_size x text_len\n",
    "input = input.permute(0,2,1)\n",
    "out = conv1(input)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch.optim\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "torch.manual_seed(2022)\n",
    "# np.random.seed(2022) # np的随机性。\n",
    "# random.seed(2022) # python的随机性\n",
    "\n",
    "#########\n",
    "#本实验中的G-mean是我的评价指标\n",
    "#########\n",
    "class Tudui(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Tudui, self).__init__()\n",
    "        self.model1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),  # torch.Size([128, 16, 5])\n",
    "            nn.Conv1d(16, 32, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),  # torch.Size([128, 32, 1])\n",
    "            nn.Flatten(),  # torch.Size([128, 32])    (假如上一步的结果为[128, 32, 2]， 那么铺平之后就是[128, 64])\n",
    "        )\n",
    "        self.model2 = nn.Sequential(\n",
    "            nn.Linear(in_features=32, out_features=2, bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = input.reshape(-1,1,11)   #结果为[128,1,11]  目的是把二维变为三维数据\n",
    "        x = self.model1(input)\n",
    "        x = self.model2(x)\n",
    "        return x\n",
    "\n",
    "data = pd.read_csv(\"../dataset/train.csv\")\n",
    "dataset = data.values\n",
    "X_train = dataset[:,1:12].astype(float)\n",
    "Y_train = dataset[:,0:1]\n",
    "encoder = LabelEncoder()\n",
    "Y_train = encoder.fit_transform(Y_train.ravel())\n",
    "\n",
    "X_train, Y_train = torch.FloatTensor(X_train), torch.LongTensor(Y_train)\n",
    "train_dataset =  torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"../dataset/test.csv\")\n",
    "dataset = data.values\n",
    "X_test = dataset[:,1:12].astype(float)\n",
    "Y_test = dataset[:,0:1]\n",
    "encoder = LabelEncoder()\n",
    "Y_test = encoder.fit_transform(Y_test.ravel())\n",
    "X_test, Y_test = torch.FloatTensor(X_test), torch.LongTensor(Y_test)\n",
    "test_dataset =  torch.utils.data.TensorDataset(X_test, Y_test)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=4444, shuffle=True)\n",
    "\n",
    "tudui = Tudui()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 1000\n",
    "learning_rate = 0.001\n",
    "optim = torch.optim.Adam(tudui.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(\"--------第{}轮训练开始---------\".format(i+1))\n",
    "    total_G_mean = 0\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
    "    tudui.train()\n",
    "    for data in train_loader:\n",
    "        X_data, Y_data = data[0], data[1]\n",
    "        output = tudui(X_data)\n",
    "        loss = loss_function(output, Y_data)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        pred = output.argmax(axis=1)\n",
    "        matrix = confusion_matrix(Y_data, pred)\n",
    "        TN = matrix[0][0]\n",
    "        FP = matrix[0][1]\n",
    "        FN = matrix[1][0]\n",
    "        TP = matrix[1][1]\n",
    "\n",
    "        FDR = TP / (TP + FN)\n",
    "        FAR = FP / (FP + TN)\n",
    "        P = TN / (TN + FP)\n",
    "        G_mean = math.sqrt(FDR * P)\n",
    "        if np.isnan(G_mean):\n",
    "            G_mean = 0.0\n",
    "\n",
    "        total_G_mean = total_G_mean + G_mean\n",
    "\n",
    "    length = len(train_loader)\n",
    "    total_G_mean = total_G_mean / length\n",
    "    print(\"G-mean为{:.4f}\".format(total_G_mean))\n",
    "\n",
    "\n",
    "# 验证数据\n",
    "    if (i + 1) % 10 == 0:\n",
    "        G_mean_test = 0\n",
    "        total_G_mean_test = 0\n",
    "        total_FDR = 0\n",
    "        total_FAR = 0\n",
    "        tudui.eval()\n",
    "        with torch.no_grad():\n",
    "            for test in test_loader:\n",
    "                X_test_data, Y_test_data = test[0], test[1]\n",
    "                out = tudui(X_test_data)\n",
    "                loss = loss_function(out, Y_test_data)\n",
    "\n",
    "                pred_test = out.argmax(axis=1)\n",
    "                matrix = confusion_matrix(Y_test_data, pred_test)\n",
    "                TN = matrix[0][0]\n",
    "                FP = matrix[0][1]\n",
    "                FN = matrix[1][0]\n",
    "                TP = matrix[1][1]\n",
    "                FDR = TP / (TP + FN)\n",
    "                FAR = FP / (FP + TN)\n",
    "                P = TN / (TN + FP)\n",
    "                G_mean_test = math.sqrt(FDR * P)\n",
    "                if np.isnan(G_mean_test):\n",
    "                    G_mean_test = 0.0\n",
    "                total_G_mean_test = total_G_mean_test + G_mean_test\n",
    "\n",
    "        total_G_mean_test = total_G_mean_test / len(test_loader)\n",
    "\n",
    "        print(\"**********************验证数据***********************\")\n",
    "        print(\"G-mean在测试集上的表现为{:.4f}\".format(total_G_mean_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4280, 946)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_test = pd.read_csv(r'C:\\Users\\Lee\\Desktop\\新建文件夹\\01-SQUAT-1Char00.calc',header=2,delim_whitespace=True)\n",
    "\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_test.columns:\n",
    "    if int(i.partition('-')[0]) < 3:\n",
    "        print(int(i.partition('-')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>01-X-x</th>\n",
       "      <th>01-X-y</th>\n",
       "      <th>01-X-z</th>\n",
       "      <th>01-V-x</th>\n",
       "      <th>01-V-y</th>\n",
       "      <th>01-V-z</th>\n",
       "      <th>01-Q-s</th>\n",
       "      <th>01-Q-x</th>\n",
       "      <th>01-Q-y</th>\n",
       "      <th>01-Q-z</th>\n",
       "      <th>...</th>\n",
       "      <th>59-Q-s</th>\n",
       "      <th>59-Q-x</th>\n",
       "      <th>59-Q-y</th>\n",
       "      <th>59-Q-z</th>\n",
       "      <th>59-A-x</th>\n",
       "      <th>59-A-y</th>\n",
       "      <th>59-A-z</th>\n",
       "      <th>59-W-x</th>\n",
       "      <th>59-W-y</th>\n",
       "      <th>59-W-z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.1168</td>\n",
       "      <td>-0.4231</td>\n",
       "      <td>0.9293</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>-0.0010</td>\n",
       "      <td>-2.8744</td>\n",
       "      <td>-0.0094</td>\n",
       "      <td>-0.0314</td>\n",
       "      <td>-0.6173</td>\n",
       "      <td>-0.7861</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.1168</td>\n",
       "      <td>-0.4231</td>\n",
       "      <td>0.9293</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>-0.0011</td>\n",
       "      <td>-2.8741</td>\n",
       "      <td>-0.0094</td>\n",
       "      <td>-0.0314</td>\n",
       "      <td>-0.6173</td>\n",
       "      <td>-0.7861</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.1168</td>\n",
       "      <td>-0.4231</td>\n",
       "      <td>0.9294</td>\n",
       "      <td>-0.0041</td>\n",
       "      <td>-0.0009</td>\n",
       "      <td>-2.8694</td>\n",
       "      <td>-0.0082</td>\n",
       "      <td>-0.0315</td>\n",
       "      <td>-0.6171</td>\n",
       "      <td>-0.7862</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.1168</td>\n",
       "      <td>-0.4231</td>\n",
       "      <td>0.9293</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>-0.0013</td>\n",
       "      <td>-2.8719</td>\n",
       "      <td>-0.0083</td>\n",
       "      <td>-0.0315</td>\n",
       "      <td>-0.6171</td>\n",
       "      <td>-0.7862</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.1167</td>\n",
       "      <td>-0.4231</td>\n",
       "      <td>0.9293</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>-2.8708</td>\n",
       "      <td>-0.0083</td>\n",
       "      <td>-0.0317</td>\n",
       "      <td>-0.6170</td>\n",
       "      <td>-0.7863</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 946 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   01-X-x  01-X-y  01-X-z  01-V-x  01-V-y  01-V-z  01-Q-s  01-Q-x  01-Q-y  \\\n",
       "0 -0.1168 -0.4231  0.9293  0.0046 -0.0010 -2.8744 -0.0094 -0.0314 -0.6173   \n",
       "1 -0.1168 -0.4231  0.9293  0.0038 -0.0011 -2.8741 -0.0094 -0.0314 -0.6173   \n",
       "2 -0.1168 -0.4231  0.9294 -0.0041 -0.0009 -2.8694 -0.0082 -0.0315 -0.6171   \n",
       "3 -0.1168 -0.4231  0.9293  0.0029 -0.0013 -2.8719 -0.0083 -0.0315 -0.6171   \n",
       "4 -0.1167 -0.4231  0.9293  0.0027 -0.0012 -2.8708 -0.0083 -0.0317 -0.6170   \n",
       "\n",
       "   01-Q-z  ...  59-Q-s  59-Q-x  59-Q-y  59-Q-z  59-A-x  59-A-y  59-A-z  \\\n",
       "0 -0.7861  ...     1.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1 -0.7861  ...     1.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2 -0.7862  ...     1.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3 -0.7862  ...     1.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4 -0.7863  ...     1.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   59-W-x  59-W-y  59-W-z  \n",
       "0     0.0     0.0     0.0  \n",
       "1     0.0     0.0     0.0  \n",
       "2     0.0     0.0     0.0  \n",
       "3     0.0     0.0     0.0  \n",
       "4     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 946 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "865d8b2eb28e274047ba64063dfb6a2aabf0dfec4905d304d7a76618dae6fdd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
